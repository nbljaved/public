#+title: Software Design by Example
#+subtitle: A Tool-Based Introduction with Python
#+auto_tangle: t
#+startup: overview
https://third-bit.com/sdxpy/

* Chapter 2: Objects and Classes
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/oop/
:header-args:python: :session ch2 :results output :async yes
:END:
** Theory
*** Intro

#+CAPTION: Python class example (with inheritance)
#+begin_src python
import math

class Shape:
    def __init__(self, name):
        self.name = name

    def perimeter(self):
        raise NotImplementedError

    def area(self):
        raise NotImplementedError

    def density(self, weight):
        return weight / self.area()

class Square(Shape):
    def __init__(self, name, side):
        super().__init__(name)
        self.side = side

    def perimeter(self):
        return 4 * self.side

    def area(self):
        return self.side ** 2

class Circle(Shape):
    def __init__(self, name, radius):
        super().__init__(name)
        self.radius = radius

    def perimeter(self):
        return 2 * math.pi * self.radius

    def area(self):
        return math.pi * (self.radius ** 2)

#+end_src

#+RESULTS:

<<making constructors>>
- NOTE :: How in the subclasses' constructor we have to *manually*
  1. mention the arguments (to ~__init__~) and
  2. call the ~super~ method

Since =Square= and =Circle= have the same methods, we can use them interchangibly.
This is called *polymorphism*.
It reduces cognitive load by allowing the people using related things to ignore their differences:

#+begin_src python
examples = [Square("sq", 3), Circle("ci", 2)]
for thing in examples:
    n = thing.name
    p = thing.perimeter()
    a = thing.area()
    d = thing.density(5)
    print(f"{n} has perimeter {p:.2f}, area {a:.2f} and density {d:.2f}")
#+end_src

#+RESULTS:
: sq has perimeter 12.00, area 9.00 and density 0.56
: ci has perimeter 12.57, area 12.57 and density 0.40

*** Using dictionary to implement polymorphism
:PROPERTIES:
:ID:       c5c68489-11e0-4960-bb9b-f003d127ac63
:header-args:python: :session ch2 :results output :eval no :async yes
:END:

#+CAPTION: Concept map for implementing objects and classes
[[file:images/Chapter_2:_Objects_and_Classes/2025-08-17_15-49-47_screenshot.png]]

#+NAME: my-classes
#+begin_src python :noweb yes :eval yes
from pprint import pprint

<<my-class-methods>>
<<my-class-constructors>>
<<generic-make-method>>

MyShape = {
    # methods
    "density": shape_density,# this method will be inherited
    # metadata
    "_classname": "MyShape", # obj._classname will tell the class of an object
    "_new": make_my_shape,
    "_parent": None, # obj._parent will is parent class of this object's class
}

MySquare = {
    "perimeter": square_perimeter,
    "area": square_area,
    # metadata
    "_new": make_my_square,
    "_classname": "MySquare",
    "_parent": MyShape,
}

MyCircle = {
    "perimeter": circle_perimeter,
    "area": circle_area,
    # metadata
    "_new": make_my_circle,
    "_classname": "MyCircle",
    "_parent": MyShape,
}

pprint(make(MyCircle, 'cute circle', radius=2))
pprint(make(MySquare, 'stupid square', side=4))
#+end_src

#+RESULTS: my-classes
#+begin_example
{'class': {'_classname': 'MyCircle',
           '_new': <function make_my_circle at 0x7ed8a19349a0>,
           '_parent': {'_classname': 'MyShape',
                       '_new': <function make_my_shape at 0x7ed8a19345e0>,
                       '_parent': None,
                       'density': <function shape_density at 0x7ed8a19351c0>},
           'area': <function circle_area at 0x7ed8a1934fe0>,
           'perimeter': <function circle_perimeter at 0x7ed8a1934ae0>},
 'name': 'cute circle',
 'radius': 2}
{'class': {'_classname': 'MySquare',
           '_new': <function make_my_square at 0x7ed8a19360c0>,
           '_parent': {'_classname': 'MyShape',
                       '_new': <function make_my_shape at 0x7ed8a19345e0>,
                       '_parent': None,
                       'density': <function shape_density at 0x7ed8a19351c0>},
           'area': <function square_area at 0x7ed8a1937e20>,
           'perimeter': <function square_perimeter at 0x7ed8a1937240>},
 'name': 'stupid square',
 'side': 4}
#+end_example

Our classes only define:
+ ~_classname~ :: the class' name
+ ~_new~ :: their constructor
  - NOTE :: requires the Class, which in turn requires this constructor, but it works :)
+ ~_parent~ :: reference to their parent class.
  Therefore, we also /automatically/ inherit the method's of the parent class.
+ the class' methods

#+CAPTION: Constructors for MySquare and MyCircle
#+NAME: my-class-constructors
#+begin_src python :noweb yes
def make(cls, *args, **kwargs):
    """
    Generic make function
    """
    return cls['_new'](*args, **kwargs)

def make_my_shape(name):
    return {
        "name": name,
        "class": MyShape,
    }

def make_my_square(name, side):
    # calling the super method
    # assigning new attributes
    #
    # MySquare overwrites the 'class' key
    # (we use '|' to combine 2 dicts)
    return make(MyShape, name) | {
        "side": side,
        "class": MySquare,
    }

def make_my_circle(name, radius):
    return make(MyShape, name) | {
        "radius": radius,
        "class": MyCircle,
    }
#+end_src

Each class constructor only defines:
+ ~class~ :: reference to its class
+ its attributes (_all manual_)
  See [[making constructors]]
  - NOTE :: Here we are mentioning all the attributes, even those of the parent class.
    - This is a *manual* step.
      When making the constructor for some class, we need to /THINK/ about its parent class and the arguments of that class' constructor.
      (Also, Python can only have one ~__init__~  method)

#+CAPTION: Methods for MyShape, MySquare, MyCircle
#+NAME: my-class-methods
#+begin_src python
# In the below function the 'self' represents the obj
def shape_density(self, weight):
    return weight / call_method(self, "area")

def square_perimeter(self):
    return 4 * self['side']

def square_area(self):
    return self['side'] ** 2

def circle_perimeter(self):
    return 2 * math.pi * self['radius']

def circle_area(self):
    return math.pi * (self['radius'] ** 2)
#+end_src

- Notice how some 'Shape' object would call its 'density' method:
  ~obj["density"](obj, weight)~

  which is very similar to:
  ~obj.density(weight)~ (here the 'self' object passed is implicit)

  - Also, not the definition of the 'shape_density' function.
    Its arguments are the same as that of a normal class' methods.

*** call_method implementation

The call_method implementation is important as that is what ties all this together.

It has to look like ~call_method(object, method_name, method_arguments ...)~

#+NAME: call_method
#+begin_src python
def call_method(obj, method_name: str, *method_args, **method_kwargs):
    def find_method(obj, method_name):
        "Returns the method or None (if unable to find)"
        cls = obj['class']
        while cls:
            if method_name in cls:
                return cls[method_name]
            cls = cls['_parent']
        return None

    method = find_method(obj, method_name)
    print(f'calling method: {method.__name__}, with args: {method_args}, with kwargs: {method_kwargs}')
    return method(obj, *method_args, **method_kwargs)
#+end_src

#+RESULTS: call_method

#+begin_src python
examples = [make(MySquare, "sq", 3), make(MyCircle, "ci", 2)]
for ex in examples:
    n = ex["name"]
    d = call_method(ex, "density", 5)
    print(f"{n}: {d:.2f}")
    print()
#+end_src

#+RESULTS:
: calling method: shape_density, with args: (5,), with kwargs: {}
: calling method: square_area, with args: (), with kwargs: {}
: sq: 0.56
:
: calling method: shape_density, with args: (5,), with kwargs: {}
: calling method: circle_area, with args: (), with kwargs: {}
: ci: 0.40

** Questions
*** Class methods and static methods

*Q.* Explain the differences between class methods and static methods
*A.* [[https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python][StackOverflow answer]]

*Q.* Implement both using dictionaries.

We need changes:
- in the ~call_method~ function
- how we store a method
  - we have to mention the function implementation as well as the type of method it is, one of:
    - normal method ~def (self, ...)~
    - classmethod ~def (cls, ...)~
    - staticmethod ~def (...)~ (No self or cls)

* Chapter 3: Finding duplicate files
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/dup/
:header-args:python: :session ch3 :results output :async yes
:GPTEL_TOPIC: chapter-3:-finding-duplicate-files
:END:
** Summary
:PROPERTIES:
:ID:       ba463b34-d27b-4adc-a0ee-9021cd241ad9
:END:

- A hash function:
  * creates a fixed-size value from an arbitrary sequence of bytes.
  * has deterministic output, but it is not easy to predict.
  * if good, has evenly distributed output.
- A large cryptographic hash can be used to uniquely identify a file's contents.

#+caption: summarizes the key ideas in this chapter, the most important of which is that SOME ALGORITHMS ARE INTRINSICALLY BETTER THAN OTHERS.
[[file:images/Chapter_3:_Finding_duplicate_files/2025-08-18_15-14-09_screenshot.png]]

** Theory
*** Setup

#+caption: Prepare files
#+begin_src sh
mkdir -p ./src/ch3/files

$(
    cd ./src/ch3/files

    echo aaa > a1.txt
    echo aaa > a2.txt
    echo aaa > a3.txt
    echo bb > b1.txt
    echo bb > b2.txt
    echo c > c1.txt
)

ls ./src/ch3/files
#+end_src

#+RESULTS:
| a1.txt |
| a2.txt |
| a3.txt |
| b1.txt |
| b2.txt |
| c1.txt |

#+name: filenames
#+begin_src python
from pprint import pprint

filenames = [
    './src/ch3/files/a1.txt',
    './src/ch3/files/a2.txt',
    './src/ch3/files/a3.txt',
    './src/ch3/files/b1.txt',
    './src/ch3/files/b2.txt',
    './src/ch3/files/c1.txt'
]
#+end_src

*** Naive approach
If we have /N/ files.
To find all duplicate files, it will take us N-1 + N-2 + ... + 1 = O(N^2) comparisions.
Each of the comparision also involves expensive byte-by-byte comparision on files the _might_ be equal.

#+name: same-bytes
#+begin_src python
def same_bytes(file1: str, file2: str, log=False) -> bool:
    bytes1 = open(file1, 'rb').read()
    bytes2 = open(file2, 'rb').read()
    if log:
        print(bytes1)
        print(bytes2)
    return bytes1 == bytes2
#+end_src

#+begin_src python :noweb yes
<<same-bytes>>
print(same_bytes('./src/ch3/files/a1.txt', './src/ch3/files/c1.txt', log=True))
#+end_src

#+RESULTS:
: b'aaa\n'
: b'c\n'
: False

- Note ::  that the files are opened in binary mode using ~"rb"~ instead of the
  usual ~"r"~.
  - This tells Python to read the bytes exactly as they are rather than trying to convert them to characters.

#+name: naive
#+caption: O(n^2) algorithm
#+begin_src python :noweb yes
<<filenames>>
<<same-bytes>>

def find_duplicates(filenames):
    duplicates = []
    n = len(filenames)
    for i in range(n):
        file1 = filenames[i]
        for j in range(i+1, n):
            file2 = filenames[j]
            if same_bytes(file1, file2):
                duplicates.append((file1, file2))
    return duplicates

pprint(find_duplicates(filenames))
#+end_src

#+RESULTS: naive
: [('./src/ch3/files/a1.txt', './src/ch3/files/a2.txt'),
:  ('./src/ch3/files/a1.txt', './src/ch3/files/a3.txt'),
:  ('./src/ch3/files/a2.txt', './src/ch3/files/a3.txt'),
:  ('./src/ch3/files/b1.txt', './src/ch3/files/b2.txt')]

*** Hash approach
Instead of comparing every file against every other, let’s process each file once to produce a short identifier that depends only on the file’s contents and then only compare files that have the same identifier, i.e., that /might/ be equal.

If files are evenly divided into =g= groups then each group will contain roughly =N/g= files, so the total work will be roughly =g*(N/g)^2=.

Simplifying, this is =N^2/g= , so as the number of groups grows, and the overall running time should decrease.

- We can use *hashing* to split the files into groups.
  We construct IDs for files by using a /hash function/ to produce a /hash code/.

  Since bytes are just numbers, we can create a very simple hash function by adding up the bytes in a file and taking the remainder module some number (the no. of groups we want).

#+caption: A naive hash function
#+begin_src python
def naive_hash(data):
    return sum(data) % 13

example = bytes('file content', 'utf-8')
print(f'Example: {example}')

id = naive_hash(example)
print(f'id: {id} \n')

for byt in example:
    print(f'byte: {byt}')
print(f'\nsum: {sum(example)}, sum%13 = {sum(example)%13}')
#+end_src

#+RESULTS:
#+begin_example
Example: b'file content'
id: 2

byte: 102
byte: 105
byte: 108
byte: 101
byte: 32
byte: 99
byte: 111
byte: 110
byte: 116
byte: 101
byte: 110
byte: 116

sum: 1211, sum%13 = 2
#+end_example

*** Better hashing
For =g= groups we have to perform =O(N^2/g)= comparisions.
If /g = N/, i.e. for each file its id has _a unique bucket_, then our complexiy becomes =O(N)=.

- NOTE :: We have to read each file at least once anyway, so we can’t possibly do better than =O(N)=.

*Q.* How can we ensure that each unique file winds up in its own group?

*A.* Use a /cryptographic hash function/:

   - The output of such a function is completely deterministic: given the same bytes in the same order, it will always produce the same output.

   - However, the output is distributed like a uniform random variable: each possible output is equally likely, which ensures that files will be evenly distributed between groups.

- SHA256 hashing algorithm :: Given some bytes as input, this function produces a 256-bit hash, which is normally written as a 64-character (as 64x4=256) hexadecimal (4bit) string.

#+name: sha256
#+begin_src python
from hashlib import sha256

# strings must be encoded before hashing
example = bytes('some content', 'utf-8')

output = sha256(example).hexdigest()
print(output)
#+end_src

#+RESULTS: sha256
: 290f493c44f5d63d06b374d0a5abd292fae38b92cab2fae5efefe1b0e9347f56

#+name: duplicates
#+caption: O(n) algorithm
#+begin_src python :noweb yes
from hashlib import sha256
<<filenames>>

def hash_files(filenames):
    groups = dict()
    for filename in filenames:
        data = open(filename, 'rb').read()
        hash_code = sha256(data).hexdigest()
        if hash_code not in groups:
            groups[hash_code] = set()
        groups[hash_code].add(filename)
    return groups

for files in hash_files(filenames).values():
    # each set of files is a duplicate of each other
    print(files)
#+end_src

#+RESULTS: duplicates
: {'./src/ch3/files/a2.txt', './src/ch3/files/a1.txt', './src/ch3/files/a3.txt'}
: {'./src/ch3/files/b2.txt', './src/ch3/files/b1.txt'}
: {'./src/ch3/files/c1.txt'}

*** Birthday problem

The odds that two people share a birthday are 1/365 (ignoring February 29).

The odds that they don’t are therefore \(\frac{365}{365}\)x\(\frac{364}{365}\).
When we add a third person, the odds that nobody share a birthday are \(\frac{365}{365}\)x\(\frac{364}{365}\)x\(\frac{363}{365}\).

If we keep going, there’s a 50% chance of two people sharing a birthday in a group of just 23 people, and a _99.9% chance with 70 people_.

The same math can tell us how many files we need to hash before there’s a 50% chance of a collision with a 256-bit hash. According to Wikipedia, the answer is approximately 4 x 10^38 files.
We’re willing to take that risk.

** Questions
*** Odds of collision
If hashes were only 2 bits long, then the chances of collision with each successive file assuming no previous collision are:

| Number of Files | Odds of Collision |
|-----------------+-------------------|
|               1 |                0% |
|               2 |               25% |
|               3 |               50% |
|               4 |               75% |
|               5 |              100% |

*Q.* A colleague of yours says this means that if we hash four files, there’s only a 75% chance of any collision occurring. What are the actual odds?

*A.* This is _a common confusion_.

2 bits means 4 possible codes.
The odds of collision:
- #files = 1 is 0.
- #files = 2 is 1/4 (second file will collide if it takes the value of the first file)
- #files = 3 is 2/4 (third file will collide if it takes value of either of the previous files)
- #files = 4 is 3/4
- #files >= 5 is 1.

But, if we hash 4 files the odds of them not colliding is = 4/4 x 3/4 x 2/4 x 1/4 = 3/32
Therefore, the odds of their being 1 collision when hashing 4 files = 1 - 3/32 = 0.90625 i.e. 90.625%

*** Streaming

- streaming API ::
  An API that processes data in chunks rather than needing to have all of it in memory at once.
  Streaming APIs usually require handlers for events such as:
  - “start of data”,
  - “next block”, and
  - “end of data”

A streaming API delivers data one piece at a time rather than all at once. Read the documentation for the update method of hashing objects in Python’s [[https://docs.python.org/3/library/hashlib.html][hashing module]] and rewrite the duplicate finder from this chapter to use it.

#+caption: streaming hashing
#+begin_src python :noweb yes
from hashlib import sha256

m = sha256()
# => m = <sha256 _hashlib.HASH object @ 0x71eb1a40c730>

m.update(b"Nobody inspects")
m.update(b" the spammish repetition")

m.digest()
# => b'\x03\x1e\xdd}Ae\x15\x93\xc5\xfe\\\x00o\xa5u+7\xfd\xdf\xf7\xbcN\x84:\xa6\xaf\x0c\x95\x0fK\x94\x06'

m.hexdigest()
# => '031edd7d41651593c5fe5c006fa5752b37fddff7bc4e843aa6af0c950f4b9406'

sha256(b"Nobody inspects the spammish repetition").hexdigest()
# => '031edd7d41651593c5fe5c006fa5752b37fddff7bc4e843aa6af0c950f4b9406'
#+end_src

* Chapter 4: Matching patterns
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/glob/
:header-args:python: :session ch4 :results output :async yes
:header-args:sh: :session ch4-sh :results output :async yes
:END:
** Summary
:PROPERTIES:
:ID:       1e611433-31e2-4a18-800b-903d2eebc169
:END:

- Use globs and regular expressions to match patterns in text.
- Use inheritance to make matchers composable and extensible.
- Simplify code by having objects delegate work to other objects.

- Use the *Null Object pattern* to eliminate special cases in code.

- Use standard refactorings to move code from one working state to another.
- Build and check the parts of your code you are least sure of first to find out if your design will work.

#+caption: summarizes the key ideas in this chapter; we will see the *Null Object* and *Chain of Responsibility* design patterns again.
[[file:images/Chapter_4:_Matching_patterns/2025-08-18_16-54-52_screenshot.png]]

** Theory
*** Setup

#+begin_src sh
mkdir -p ./src/ch4/
#+end_src

*** Simple patterns
:PROPERTIES:
:ID:       f9f26345-73e4-4da9-a36c-0fbb127cf219
:END:

|---------+--------+--------|
| *Pattern* | *Text*   | *Match?* |
|---------+--------+--------|
| abc     | “abc”  | true   |
| ab      | “abc”  | false  |
| abc     | “ab”   | false  |
| *       | ”“     | true   |
| *       | “abc”  | true   |
| a*c     | “abc”  | true   |
| {a,b}   | “a”    | true   |
| {a,b}   | “c”    | false  |
| {a,b}   | “ab”   | false  |
| *{x,y}  | “abcx” | true   |
|---------+--------+--------|

+ Matching is conceptually simple.

  * If the first element of the pattern matches the target string at the current location, we check if the rest of the pattern matches what’s left of the string.

  * If the element doesn’t match the front of the string, or if the rest of the pattern can’t match the rest of the string, matching fails. (This behavior makes globbing different from regular expressions, which can match parts of strings.)

This design makes use of the *Chain of Responsibility* design pattern.
Each matcher matches if it can then asks the next matcher in the chain to try to match the remaining text (Figure 4.2).
Crucially, objects don’t know how long the chain after them is: they just know whom to ask next.

#+caption: matching with Chain of Responsibility
[[file:images/Chapter_4:_Matching_patterns/2025-08-18_17-34-00_screenshot.png]]

- Chain of Responsibility pattern ::
  A design pattern in which each object either handles a request or passes it on to another object.

- Null Object pattern ::
  A design pattern in which a placeholder object is used instead of /None/.

  The placeholder object has the methods of the object usually used, but those methods do 'nothing'.
  - NOTE :: 'nothing' DOESN'T mean that the return value of those methods has to be /None/.

  This pattern saves other code from having to check repeatedly for /None/.

So, we will define a base class ~Pattern~ that will have a method ~match~ which returns boolean indicating if the ~Pattern~ matches some text.
To refer to the next ~Pattern~ we will note that down in its 'rest' attribute.

#+name: base-class
#+caption: base and null object class
#+begin_src python :tangle ./src/ch4/matcher.py :noweb yes
Pattern = type('Pattern')
class Pattern:
    def __init__(self, rest: Pattern | None = None):
        """
        Subclasses of Pattern can take two arguments:
        1. set of characters, a str etc.
        2. rest (the next Pattern)
        """
        # NOTE: How we can pass the argument has None and it is handled by the
        # Null Object pattern
        self.rest : Pattern = rest if rest is not None else Null()

    def match(self, text: str) -> bool:
        """
        Returns boolean indicating if Pattern matches `text`.
        """
        length_of_matched_text = self._match(text, start=0)
        return len(text) == length_of_matched_text

    <<Pattern __eq__>>

class Null(Pattern):
    """
    Null Object Pattern
    Null() is the placeholder object instead of 'None'
    """
    def __init__(self):
        """
        Null objects must be at the end of the matching chain, i.e., their 'rest'
        must be None, so we remove the 'rest' parameter from the class’s
        constructor and pass 'None' up to the parent constructor every time.
        """
        self.rest = None # base case

    def _match(self, text, start):
        """
        Since Null objects don’t match anything, Null._match immediately returns
        whatever starting point it was given.

        Every other matcher can now pass responsibility down the chain without
        having to test whether it’s the last matcher in line or not.
        """
        return start

<<literal pattern>>
<<any pattern>>
<<either pattern>>
#+end_src

- ~Match.rest~ requires every child class to have a helper method called ~_match~ that returns the location from which searching is to continue.

- ~Match.match~ checks whether the entire match reaches the end of the target string and returns True or False as appropriate.

*** Implement Lit(Pattern)

#+caption: literal tests
#+begin_src python :tangle ./src/ch4/test_literal.py
from matcher import *

def test_literal_match_entire_string():
    # /abc/ matches "abc"
    assert Lit("abc").match("abc")

def test_literal_substring_alone_no_match():
    # /ab/ doesn't match "abc"
    assert not Lit("ab").match("abc")

def test_literal_superstring_no_match():
    # /abc/ doesn't match "ab"
    assert not Lit("abc").match("ab")
#+end_src

For the above tests we define the following ~Literal~ pattern:

#+name: literal pattern
#+begin_src python :noweb yes
class Lit(Pattern):
    def __init__(self, chars: str, rest=None):
        super().__init__(rest)
        self.chars = chars

    def _match(self, text: str, start=0):
        end = len(self.chars) + start
        if text[start:end] != self.chars:
            # failed
            #
            # this is the position to next search,
            # (therefore None means failed)
            return None
        # passed
        return self.rest._match(text, start=end)

    <<Lit __eq__>>
#+end_src


#+caption: literal test to make sure chaining is working
#+begin_src python :tangle ./src/ch4/test_literal.py
def test_literal_followed_by_literal_match():
    # /a/+/b/ matches "ab"
    assert Lit("a", Lit("b")).match("ab")

def test_literal_followed_by_literal_no_match():
    # /a/+/b/ doesn't match "ac"
    assert not Lit("a", Lit("b")).match("ac")
#+end_src


#+begin_src sh :async yes
uvx pytest ./src/ch4/test_literal.py
#+end_src

#+RESULTS:
: =============================== test session starts ================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 5 items
:
: src/ch4/test_literal.py .....                                                [100%]
:
: ================================ 5 passed in 0.01s =================================

*** Implement Any(Pattern)

#+caption: any's tests
#+begin_src python :tangle ./src/ch4/test_any.py
from matcher import *

def test_any_matches_empty():
    # /*/ matches ""
    assert Any().match("")

def test_any_matches_entire_string():
    # /*/ matches "abc"
    assert Any().match("abc")

def test_any_matches_as_prefix():
    # /*def/ matches "abcdef"
    assert Any(Lit("def")).match("abcdef")

def test_any_matches_as_suffix():
    # /abc*/ matches "abcdef"
    assert Lit("abc", Any()).match("abcdef")

def test_any_matches_interior():
    # /a*c/ matches "abc"
    assert Lit("a", Any(Lit("c"))).match("abc")
#+end_src

Keeping in mind the above tests, we write the following class:

#+name: any pattern
#+begin_src python
class Any(Pattern):
    def __init__(self, rest=None):
        super().__init__(rest)

    def _match(self, text: str, start=0):
        """
        Here '*' can match 0 or more of the characters
        in text[start:].
        Here, we implement lazy matching, '*' will match
        the shortes string so that the 'rest' of Pattern can
        successfully match 'text'.
        """
        n = len(text)
        # length matched = from 0 -> len(text[start:])
        #
        # NOTE1: i=n+1 => * matched the complete text[start:]
        #       and the 'rest' will have to match the empty string.
        for i in range(start, n+1):
            # i the index where 'rest' will start matching from,
            # i.e. 'rest' tries to match text[i:]
            #
            # if self.rest.match(text[i:]):
            #     return n
            # OR
            j = self.rest._match(text, start=i)
            if j == n: # NOTE2: why we test for this (hint we don't rely on 'rest')
                # success
                return n # NOTE3

        # fail
        return None
#+end_src

- NOTE :: In the above code
  - NOTE1
  - NOTE2
  - NOTE3

#+begin_src sh
uvx pytest ./src/ch4/test_any.py
#+end_src

#+RESULTS:
: =============================== test session starts ================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 5 items
:
: src/ch4/test_any.py .....                                                    [100%]
:
: ================================ 5 passed in 0.01s =================================

*** Implement Either(Pattern)

#+name: test either
#+begin_src python :tangle ./src/ch4/test_either.py
from matcher import *

def test_either_two_literals_first():
    # /{a,b,c}/ matches "a"
    assert Either(Lit("a"), Lit("b")).match("a")

def test_either_two_literals_not_both():
    # /{a,b,c}/ doesn't match "ab"
    assert not Either(Lit("a"), Lit("b"), Lit("c")).match("ab")

def test_either_followed_by_literal_match():
    # /{a,b,c}d/ matches "cd"
    assert Either(Lit("a"), Lit("b"), Lit("c"), rest=Lit("d")).match("cd")

def test_either_followed_by_literal_no_match():
    # /{a,b,c}d/ doesn't match "cx"
    assert not Either(Lit("a"), Lit("b"), Lit("c"), rest=Lit("d")).match("cx")

def test_either_followed_by_literal_no_match2():
    # /{a,b,cd}d/ matches "cd"
    assert not Either(Lit("a"), Lit("b"), Lit("cd"), rest=Lit("d")).match("cd")

def test_empty_either_empty_literal_match():
    # /{}/ matches ""
    assert Either().match("")

def test_empty_either_literal_match():
    # /{}abc/ matches ""
    assert Either(rest=Lit("abc")).match("abc")

def test_empty_either_literal_no_match():
    # /{}abc/ doesn't match "abd"
    assert not Either().match("abd")
#+end_src

Keeping in mind the above test cases:

#+name: either pattern
#+begin_src python
class Either(Pattern):
    def __init__(self, *patterns, rest=None):
        super().__init__(rest)
        self.patterns = patterns

    def _match(self, text, start=0):
        # NOTE: what if patterns are empty ?
        if not self.patterns:
            return self.rest._match(text, start)

        # Try each pattern
        for pattern in self.patterns:
            j = pattern._match(text, start)
            if j is None:
                continue
            if len(text) == self.rest._match(text, start=j):
                # pass
                return len(text)
        # fail
        return None
#+end_src

#+begin_src sh
uvx pytest ./src/ch4/test_either.py
#+end_src

#+RESULTS:
: =============================== test session starts ================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 8 items
:
: src/ch4/test_either.py ........                                              [100%]
:
: ================================ 8 passed in 0.01s =================================

* Chapter 5: Parsing Text
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/parse/
:header-args:python: :session ch5 :results output :async yes :eval no
:header-args:sh: :session ch5-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       6e6a4a75-8d34-4f9c-ad32-7cb0d668fd09
:END:

#+caption: Gist
#+begin_example
Tranform text -> list of tokens List[[token_type, token_args]] --parse-> either AST or actual python objects
#+end_example

 - Parsing transforms text that's easy for people to read into objects that are easy for computers to work with.
 - A grammar defines the textual patterns that a parser recognizes.

 - Most parsers tokenize input text and then analyze the tokens.
 - Most parsers need to implement some form of precedence to prioritize different patterns.

 - Operations like addition and function call work just like user-defined functions.
 - Programs can overload built-in operators by defining specially-named methods that are recognized by the compiler or interpreter.

#+caption: Parser concept map
[[file:images/Chapter_5:_Parsing_Text/2025-08-19_16-39-33_screenshot.png]]

** Theory
*** Intro
We constructed objects to match patterns in [[*Chapter 4: Matching patterns][Chapter 4: Matching patterns]], but an expression like ~"2023-*{pdf,txt}"~ is a lot easier to read and write than code like ~Lit("2023-", Any(Either("pdf", "txt")))~.

If we want to use the former, we need a parser to convert those human-readable strings into machine-comprehensible objects.

#+caption: glob grammar that our parse will handle
| *Meaning*                 | *Character* |
|-------------------------+-----------|
| Any literal character c | c         |
| Zero or more characters | *         |
| Alternatives            | {x,y}     |

When we are done, our parser should be able to recognize that =2023-*.{pdf,txt}= means the literal =2023-= , any characters, a literal =.=, and then either a literal =pdf= or a literal =txt=.

*** Tokenizing
:PROPERTIES:
:ID:       13eb27ae-7cbf-4c1d-9671-a4d69fdb3aa2
:END:

Most parsers are written in 2 parts:

1. The first stage groups characters into atoms of text called “tokens“, which are meaningful pieces of text like the digits making up a number or the letters making up a variable name.

2. The second stage of parsing assembles tokens to create an *abstract syntax tree*,
   that represents the structure of what was parsed

#+caption: Stages in parsing pipeline
[[file:images/Chapter_5:_Parsing_Text/2025-08-20_10-08-30_screenshot.png]]

Our grammars token are:
- special characters:
  - ,
  - {
  - }
  - *
- (other characters) a sequence of one or more other characters is a single multi-letter token.

The above classification determines the design of our tokenizer:

1. If a character is not special, then append it to the current literal (if there is one) or start a new literal (if there isn’t).

2. If a character is special, then close the existing literal (if there is one) and create a token for the special character. Note that the =,= character closes a literal but doesn’t produce a token.

Eg: For the string "2023-*{pdf, txt}", out tokenizer will output:
#+begin_src python
[
    ['Lit', '2023-'],
    ['Any'],
    ['EitherStart'],
    ['Lit', 'pdf'],
    ['Lit', 'txt'],
    ['EitherEnd']
]
#+end_src

We use the above structure for our tokens because they represent the pattern and the arguments that pattern takes.

#+name: tokenizer
#+begin_src python :tangle ./src/ch5/tokenizer.py
class Tokenizer():
    def __init__(self):
        self._setup()

    def _setup(self):
        # NOTE: We are defining the class attributes in a function
        #       other than __init__ !
        self.result = []
        self.current = ""

    def _add(self, thing):
        """
        Adds the current thing to the list of tokens.
        Examples of 'thing': ['Any'], ['EitherStart'], ['EitherEnd']

        As a special case, self._add(None) means “add the literal but nothing
        else”
        """
        if len(self.current) > 0:
            self.result.append(['Lit', self.current])
            self.current = ''
        if thing is not None:
            self.result.append(thing)

    def tok(self, text: str):
        """
        Main method of our tokenizer
        """
        # This method calls self._setup() at the start so that the tokenizer can
        # be re-used
        self._setup()

        for c in text:
            if c == '*':
                self._add(['Any'])
            elif c == '{':
                self._add(['EitherStart'])
            elif c == '}':
                self._add(['EitherEnd'])
            elif c == ',':
                self._add(None)
            elif c.isascii():
                self.current += c
            else:
                raise NotImplementedError(f'what is {c} ?')
        # NOTE: We do this to add the final 'current' to the 'result'.
        return self.result
#+end_src

The above class based implementation is very nice:
- we have ~_setup()~ method to *reset* the state of our /current/ and /result/ variables.
- we have ~_add(pattern_name | None)~ to add the literal (before adding the special character, if it exists).

#+name: tokenizer tests
#+begin_src python :tangle ./src/ch5/test_tokenizer.py
from .tokenizer import *

def test_tok_empty_string():
    assert Tokenizer().tok("") == []

def test_tok_any_either():
    assert Tokenizer().tok("*{abc,def}") == [
        ["Any"],
        ["EitherStart"],
        ["Lit", "abc"],
        ["Lit", "def"],
        ["EitherEnd"],
    ]
#+end_src

#+begin_src sh
uvx pytest ./src/ch5/test_tokenizer.py
#+end_src

#+RESULTS:
: ============================================================================ test session starts ============================================================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 2 items
:
: src/ch5/test_tokenizer.py ..                                                                                                                                          [100%]
:
: ============================================================================= 2 passed in 0.01s =============================================================================

*** Parsing

We now need to turn the list of tokens into a tree.

Just as we used a class for tokenizing, we will create one for parsing and give it a ~_parse~ method to start things off.
This method doesn’t do any conversion itself.
Instead, it takes a token off the front of the list and figures out which method handles tokens of that kind:

#+begin_src python :tangle ./src/ch5/parser.py
from .tokenizer import *
from ..ch4.matcher import *

class Parser():
    def __init__(self):
        pass

    def parse(self, text: str):
        tokens = Tokenizer().tok(text)
        return self._parse(tokens)

    def _parse(self, tokens):
        if not tokens:
            return Null()

        car = tokens[0]
        cdr = tokens[1:]
        pattern = car[0]
        if pattern == 'Any':
            handler = self._parse_Any
        elif pattern == 'Lit':
            handler = self._parse_Lit
        elif pattern == 'EitherStart':
            handler = self._parse_EitherStart
        else:
            assert False, f'Unknown token type {pattern}'

        return handler(car[1:], cdr)

    def _parse_Any(self, arg, rest_tokens):
        return Any(rest=self._parse(rest_tokens))

    def _parse_Lit(self, arg, rest_tokens):
        text = arg[0]
        return Lit(chars=text, rest=self._parse(rest_tokens))

    def _parse_EitherStart(self, arg, rest_tokens):
        args = [] # with store the options of Either

        for i in range(len(rest_tokens)):
            token = rest_tokens[i]
            if token[0] == 'EitherEnd':
                either_end_index = i
                break
            else:
                pattern = self._parse([token])
                args.append(pattern)

        return Either(*args, rest=self._parse(rest_tokens[either_end_index+1:]))
#+end_src

Now let's write a test to test our implementation of ~Parser~:

#+begin_src python :tangle ./src/ch5/test_parser.py
from .parser import *
from ..ch4.matcher import *

def test_parse_either_two_lit():
    assert Parser().parse("{abc,def}") == Either(
        [Lit("abc"), Lit("def")]
    )
#+end_src

To run the above test, we need to first implement *equal* operation by the ~Pattern~ class.

This test assumes we can compare ~Pattern~ objects using ====, just as we would compare numbers or strings. so we add a ~__eq__~ method to our classes:

#+name: Pattern __eq__
#+begin_src python
def __eq__(self, other):
    return (other is not None
            and self.__class__ == other.__class__
            and self.rest == other.rest)
#+end_src

#+name: Lit __eq__
#+begin_src python
def __eq__(self, other):
    return super().__eq__(other) and (self.chars == other.chars)

#+end_src

In the above Note:
- definition of ~__eq__(self, other)~
- usage of ~__class__~
- usage of ~super().__eq__(other)__~

- Since we’re using inheritance to implement our matchers, we write the check for equality in two parts.

  1. The parent class ~Pattern~ performs the checks that all classes need to perform (in this case, that the objects being compared have the same /concrete class/).

  2. If the child class needs to do any more checking (for example, that the characters in two ~Lit~ objects are the same) it calls up to the parent method first, then adds its own tests.

#+begin_src sh
uvx pytest ./src/ch5/test_parser.py
#+end_src

#+RESULTS:
: ============================================================================ test session starts ============================================================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 1 item
:
: src/ch5/test_parser.py .                                                                                                                                              [100%]
:
: ============================================================================= 1 passed in 0.01s =============================================================================
** Questions
*** Nested Lists
*Q.* Write a function that accepts a string representing nested lists containing numbers and returns the actual list. For example, the input [1, [2, [3, 4], 5]] should produce the corresponding Python list.

*A.* convert the text into:
#+begin_src python
# [1, [2, [3, 4], 5]]
# is converted to
[
    ['ListStart'],
    ['Number', '1'],
    ['ListStart'],
    ['Number', '2'],
    ['ListStart'],
    ['Number', '3'],
    ['Number', '4'],
    ['ListEnd'],
    ['Number', '5'],
    ['ListEnd'],
    ['ListEnd'],
]
#+end_src


#+begin_src python :eval yes

def isnumber(text: str) -> bool:
    "Returns True if text represents a integer or decimal number"
    try:
        float(text)
        return True
    except:
        return False

def tokenize(text: str):
    current = ""
    result = []

    def add(token):
        """
        Add current to 'result', then adds 'token' to 'result'
        """
        nonlocal current
        if len(current) > 0:
            result.append(['Number', current])
            current = ''
        if token is not None:
            result.append(token)

    for char in text:
        if char == '[':
            # special tokens like these signal the end of 'current'
            # as well as need to be taken care of themselves
            add(['ListStart'])
        elif char == ']':
            add(['ListEnd'])
        elif char == ',':
            # ',' signals the end of 'current'
            add(None)
        elif char.isspace():
            # if i just ignore it
            # then [2 2] would represent [22],
            # but let's ignore that for now
            continue
        elif isnumber(current + char):
            current += char
        else:
            raise NotImplementedError(f'what is this char: {char} ?')

    add(None)
    return result

expected = [
    ['ListStart'],
    ['Number', '1'],
    ['ListStart'],
    ['Number', '2'],
    ['ListStart'],
    ['Number', '3'],
    ['Number', '4'],
    ['ListEnd'],
    ['Number', '5'],
    ['ListEnd'],
    ['ListEnd'],
]
actual = tokenize('[1, [2, [3, 4], 5]]')
print(actual == expected)
#+end_src

#+RESULTS:
: True

To parse this one has to process the list of tokens and call individual parse helper methods recursively.

*** Simple Arithmetic
*Q.*
Write a function that accepts a string consisting of numbers and the basic arithmetic operations +, -, *, and /, and produces a nested structure showing the operations in the correct order.

For example, 1 + 2 * 3 should produce ["+", 1, ["*", 2, 3]].

*A.* Here operations have a relative ordering, it is NOT simply left to right.

#+begin_src python
# For  "1 + 2 * 3"
# we get
[
    ['Number', '1'],
    ['+'],
    ['Number', '2'],
    ['*'],
    ['Number', '3'],
]
#+end_src

- NOTE :: Maybe we also have brackets "(1 + 2) * 3"

So, there is an ordering:
1. Brackets
2. Division
3. Multiplication
4. Addition
5. Subtraction

- Aim :: Is to convert this list of tokens into an AST, keeping in the above order of operations in mind.

Let's assume our string is:
#+begin_src python
example = '(3 + 3) / -.6 - -10 * 1.0'
#+end_src

In the above 'example', we have operations, numbers, and spaces.
- In this string, spaces shouldn't matter (assuming we have been given valid syntax)
- Therefore, our string only has number stuff(digits, decimal, and negative) and operations

#+name: tokenize arithmetic
#+begin_src python :tangle ./src/ch5/tokenize_arithmetic.py
from pprint import pprint

def tokenize(text: str):
    result = []
    current = ''

    def looking_for_number() -> bool:
        """
        Return true if 'result's last token is an operation
        """
        if not result:
            return False
        last_token = result[-1]
        # check if it is a number
        if last_token[0] == 'Number':
            return

    def add(token):
        nonlocal current
        if len(current) > 0:
            result.append(['Number', current])
            current = ''
        if token:
            result.append(token)

    for i, char in enumerate(text):
        if char == '(':
            add(['('])
        elif char == ')':
            add([')'])
        elif char == '+':
            add(['+'])
        elif char == '*':
            add(['*'])
        elif char == '/':
            add(['/'])
        elif char.isspace():
            continue
        # number can be '0-9',
        elif char.isdigit():
            current += char
        elif char == '.':
            if '.' not in current:
                current += char
            else:
                raise Exception(f'you promised valid string')
        elif char == '-':
            # now either this is the minus operation
            # or negative on a number
            #
            # If 'current' is empty => negative
            # If 'current' is not empty => minus operation
            if current:
                add(['-'])
            else:
                current += '-'
        else:
            raise Exception(f'provided text: {text} is supposed to be valid')

    add(None)
    return result
#+end_src

#+begin_src python :eval yes :noweb yes
<<tokenize arithmetic>>
example = '(3 + 3) / -.6 - -10 * 1.0'

pprint(tokenize(example))
#+end_src

#+RESULTS:
#+begin_example
[['('],
 ['Number', '3'],
 ['+'],
 ['Number', '3'],
 [')'],
 ['/'],
 ['Number', '-.6'],
 ['-'],
 ['Number', '-10'],
 ['*'],
 ['Number', '1.0']]
#+end_example

Now what remains is to convert this list of token into the requested AST.
To do that we will not parse left-to-right, but we will go through the tokens parsing (ruling out) each operation one by one.

#+name: parse arithmetic
#+begin_src python :noweb yes :tangle ./src/ch5/parse_arithmetic.py
from .tokenize_arithmetic import *

<<parsed arithmetic classes>>

<<handle bracket>>

<<handle division>>

<<handle multiplication>>

<<handle addition>>

<<handle subtraction>>

def parse_token(token) -> Parsed:
    if isinstance(token, Parsed):
        return token
    # either is an operation
    # or is a number
    if token[0] == 'Number':
        return Number(value=token[1])

    # token must be an operation
    # We can't parse an operation in isolation
    raise Exception(f'Cannot process operation: {token} in isolation')

def parse(tokens):
    tokens = handle_bracket(tokens)
    tokens = handle_division(tokens)
    tokens = handle_multiplication(tokens)
    tokens = handle_addition(tokens)
    tokens = handle_subtraction(tokens)
    return tokens


#+end_src

#+name: parsed arithmetic classes
#+begin_src python
from dataclasses import dataclass

class Parsed:
    pass

@dataclass
class Number(Parsed):
    value: str

    def __call__(self):
        return self.value

class Operation(Parsed):
    def __call__(self):
        return [self.op, self.left(), self.right()]

@dataclass
class Add(Operation):
    left: Parsed
    right: Parsed
    op: str = '+'

@dataclass
class Subtract(Operation):
    left: Parsed
    right: Parsed
    op: str = '-'

@dataclass
class Multiply(Operation):
    left: Parsed
    right: Parsed
    op: str = '*'

@dataclass
class Divide(Operation):
    left: Parsed
    right: Parsed
    op: str = '*'
#+end_src

#+name: handle bracket
#+begin_src python
def find_bracket_end(tokens, bracket_open_index):
    opened = 1
    for i in range(bracket_open_index+1, len(tokens)):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '(':
            opened += 1
        elif isinstance(token, list) and token[0] == ')':
            opened -= 1
            if opened == 0:
                return i

    raise Exception(f'Could not find corresponding closing bracket for open bracket at index: {bracket_open_index}')

def handle_bracket(tokens):
    i = 0
    while i < len(tokens):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '(':
            # we have to first parse everything inside this
            # '(' ... ')' pair
            # to find its bracket end
            j = find_bracket_end(tokens, i)
            tokens[i:j+1] = parse(tokens[i+1:j])
            #
            i = i
        else:
            i += 1
    return tokens
#+end_src

#+name: handle division
#+begin_src python
def handle_division(tokens):
    # a / b / c => (a / b) / c
    i = 0
    while i < len(tokens):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '/':
            left, right = tokens[i-1], tokens[i+1]
            tokens[i-1:i+2] = [Divide(left=parse_token(left),
                                     right=parse_token(right))]
            # 3 tokens replaced by 1
            # 0 1 2 3(/) 4
            # 0 1 2=23(/)4 3
            i = i
            continue
        else:
            i += 1

    return tokens
#+end_src

#+name: handle multiplication
#+begin_src python
def handle_multiplication(tokens):
    i = 0
    while i < len(tokens):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '*':
            left, right = tokens[i-1], tokens[i+1]
            tokens[i-1:i+2] = [Multiply(left=parse_token(left),
                                       right=parse_token(right))]
            i = i
            continue
        else:
            i += 1
    return tokens
#+end_src

#+name: handle addition
#+begin_src python
def handle_addition(tokens):
    i = 0
    while i < len(tokens):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '+':
            left, right = tokens[i-1], tokens[i+1]
            tokens[i-1:i+2] = [Add(left=parse_token(left),
                                  right=parse_token(right))]
            i = i
            continue
        else:
            i += 1
    return tokens
#+end_src

#+name: handle subtraction
#+begin_src python
def handle_subtraction(tokens):
    i = 0
    while i < len(tokens):
        token = tokens[i]
        if isinstance(token, list) and token[0] == '-':
            left, right = tokens[i-1], tokens[i+1]
            tokens[i-1:i+2] = [Subtract(left=parse_token(left),
                                       right=parse_token(right))]
            i = i
            continue
        else:
            i += 1
    return tokens
#+end_src

Time to test it now:

#+begin_src python :tangle ./src/ch5/test_arithmetic.py
from .parse_arithmetic import *
from .tokenize_arithmetic import *
from pprint import pprint

def test_tokenize():
    example = '(3 + 3) / -.6 - -10 * 1.0'
    expected = [['('],
                ['Number', '3'],
                ['+'],
                ['Number', '3'],
                [')'],
                ['/'],
                ['Number', '-.6'],
                ['-'],
                ['Number', '-10'],
                ['*'],
                ['Number', '1.0']]
    actual = tokenize(example)
    assert actual == expected

def test_parse():
    example = '(3 + 3) / -.6 - -10 * 1.0'
    tokens = tokenize(example)
    actual = parse(tokens)
    expected = [Subtract(left=Divide(left=Add(left=Number(value='3'),
                                              right=Number(value='3'),
                                              op='+'),
                                     right=Number(value='-.6'),
                                     op='*'),
                         right=Multiply(left=Number(value='-10'),
                                        right=Number(value='1.0'),
                                        op='*'),
                         op='-')]
    assert actual == expected

def test_ast():
    example = '(3 + 3) / -.6 - -10 * 1.0'
    tokens = tokenize(example)
    parsed_list = parse(tokens)
    actual = parsed_list[0]()
    expected = ['-', ['*', ['+', '3', '3'], '-.6'], ['*', '-10', '1.0']]
    assert actual == expected

#+end_src

- NOTE :: ~@dataclass~ also implements equality, good for me

* Chapter 6: Running Tests
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/test/
:header-args:python: :session ch6 :results output :async yes :eval no
:header-args:sh: :session ch6-sh :results output :async yes
:END:
** Summary
:PROPERTIES:
:ID:       09c1b9b4-68ef-4107-8e92-920827954bee
:END:

- Functions are objects you can save in data structures or pass to other functions.

- Python stores local and global variables in dictionary-like structures.

- A unit test performs an operation on a fixture and passes, fails, or produces an error.
- A program can use introspection to find functions and other objects at runtime.

#+caption: Concept map
[[file:images/Chapter_6:/2025-08-21_09-57-47_screenshot.png]]

When reviewing the ideas introduced in this chapter, it’s worth remembering /Clarke’s Third Law/, which states that any sufficiently advanced technology is indistinguishable from magic.

The same is true of programming tricks like *introspection*: the code that finds tests dynamically seems transparent to an expert who _understands that CODE IS DATA_, but can be incomprehensible to a novice.

** Theory
*** Storing and running tests
A function is just an object that we can assign to a variable. We can also store them in lists just like numbers or strings.

#+begin_src python :eval yes
def first():
    print("First")

def second():
    print("Second")

def third():
    print("Third")

everything = [first, second, third]
for func in everything:
    func()
#+end_src

#+RESULTS:
: First
: Second
: Third

However, we have to be able to call the functions in the same way in order for this trick to work, which means they must have the same signature.

Now suppose we have a function we want to test:

#+name: def sign
#+begin_src python
def sign(value):
    if value < 0:
        return -1
    else:
        return 1
#+end_src

and some functions that test it (two of which contain deliberate errors):

#+name: some-test-cases
#+begin_src python
def test_sign_negative():
    assert sign(-3) == -1

def test_sign_positive():
    assert sign(19) == 1

def test_sign_zero():
    assert sign(0) == 0

def test_sign_error():
    assert sgn(1) == 1
#+end_src

- Fixture :: The thing on which a test is run, such as the parameters to the function being tested or the file being processed.

- Each test does something to a *fixture* (such as the number 19) and uses assertions to compare the /actual/ result against the /expected/ result. The outcome of each test can be:

  * Pass :: the test subject works as expected.
  * Fail :: something is wrong with the test subject.
  * Error :: something is wrong in the test itself, which means we don’t know if the thing we’re testing is working properly or not.

- We can implement this classification scheme as follows:

  1. If a test function completes without /raising/ any kind of /exception/, it passes. (We don’t care if it returns something, but _by convention_ tests don’t return a value.)

  2. If the function raises an =AssertionError= exception, then the test has failed. Python’s ~assert~ statement does this automatically when the condition it is checking is false, so almost all tests use ~assert~ for checks.

  3. If the function raises any other kind of exception, then we assume the test itself is broken and count it as an error.

Translating these rules into code gives us the function 'run_tests' that runs every test in a list and counts how many outcomes of each kind it sees:

#+name: run_tests
#+begin_src python
def run_tests(all_tests):
    results = {"pass": 0, "fail": 0, "error": 0}
    for test in all_tests:
        try:
            test()
            results["pass"] += 1
        except AssertionError:
            results["fail"] += 1
        except Exception:
            results["error"] += 1
    print(f"pass {results['pass']}")
    print(f"fail {results['fail']}")
    print(f"error {results['error']}")
#+end_src

We use run_tests by putting all of our test functions into a list and passing that to the test runner:

#+begin_src python :noweb yes :eval yes
<<def sign>>
<<some-test-cases>>

<<run_tests>>

TESTS = [
    test_sign_negative,
    test_sign_positive,
    test_sign_zero,
    test_sign_error
]

run_tests(TESTS)

#+end_src

#+RESULTS:
: pass 2
: fail 1
: error 1

- NOTE :: *Independence*
  Our function runs tests in the order they appear in the list.

  The tests _SHOULD NOT_ rely on that: every unit test should work independently so that an error or failure in an early test doesn’t affect other tests’ behavior.

*** Finding functions

Making lists of functions is clumsy and error-prone: sooner or later we’ll add a function to TESTS twice or forget to add it at all.

We’d therefore like our test runner to find tests for itself, which it can do by exploiting the fact that Python stores variables in a structure similar to a dictionary.

#+caption: Using the 'globals' function
#+begin_src python :eval yes :session ch6-globals
import pprint
pprint.pprint(globals())
#+end_src

#+RESULTS:
#+begin_example
{'__PYTHON_EL_eval': <function __PYTHON_EL_eval at 0x780ae95c2ac0>,
 '__PYTHON_EL_eval_file': <function __PYTHON_EL_eval_file at 0x780ae95c2b60>,
 '__PYTHON_EL_native_completion_setup': <function __PYTHON_EL_native_completion_setup at 0x780ae95c2f20>,
 '__annotations__': {},
 '__builtins__': <module 'builtins' (built-in)>,
 '__doc__': None,
 '__loader__': <class '_frozen_importlib.BuiltinImporter'>,
 '__name__': '__main__',
 '__org_babel_python_format_value': <function __org_babel_python_format_value at 0x780ae95c2980>,
 '__package__': None,
 '__spec__': None,
 'pprint': <module 'pprint' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/pprint.py'>,
 'readline': <module 'readline' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/lib-dynload/readline.cpython-311-x86_64-linux-gnu.so'>,
 'tty': <module 'tty' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/tty.py'>}
#+end_example

As the output shows, ~globals~ is a dictionary containing all the variables in the program’s /global scope/.

(See how the module ~pprint~ was imported)

Since we just started the interpreter, all we see are the variables that Python defines automatically.

*Q.* What happens when we define a variable of our own ?

#+begin_src python :eval yes :session ch6-globals
import pprint
my_variable = 123
def my_function(x,y):
    pass
pprint.pprint(globals())
#+end_src

#+RESULTS:
#+begin_example
{'__PYTHON_EL_eval': <function __PYTHON_EL_eval at 0x780ae95c2ac0>,
 '__PYTHON_EL_eval_file': <function __PYTHON_EL_eval_file at 0x780ae95c2b60>,
 '__PYTHON_EL_native_completion_setup': <function __PYTHON_EL_native_completion_setup at 0x780ae95c2f20>,
 '__annotations__': {},
 '__builtins__': <module 'builtins' (built-in)>,
 '__doc__': None,
 '__loader__': <class '_frozen_importlib.BuiltinImporter'>,
 '__name__': '__main__',
 '__org_babel_python_format_value': <function __org_babel_python_format_value at 0x780ae95c2980>,
 '__package__': None,
 '__spec__': None,
 'my_function': <function my_function at 0x780ae95c2e80>,
 'my_variable': 123,
 'pprint': <module 'pprint' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/pprint.py'>,
 'readline': <module 'readline' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/lib-dynload/readline.cpython-311-x86_64-linux-gnu.so'>,
 'tty': <module 'tty' from '/gnu/store/c5qarpvwzcz1idryvvpiqd7738jn4rs1-python-3.11.11/lib/python3.11/tty.py'>}
#+end_example

If function names are just variables and a program’s variables are stored in a dictionary, we can loop over that dictionary to find all the functions whose names start with 'test_':

#+name: def find-tests
#+begin_src python
def find_tests(prefix):
    for (name, func) in globals().items():
        if name.startswith(prefix):
            print(name, func)
#+end_src

#+begin_src python :noweb yes :eval yes
<<def find-tests>>
find_tests("test_")
#+end_src

#+RESULTS:
: test_sign_negative <function test_sign_negative at 0x7eefe1110900>
: test_sign_positive <function test_sign_positive at 0x7eefe1110cc0>
: test_sign_zero <function test_sign_zero at 0x7eefe1110d60>
: test_sign_error <function test_sign_error at 0x7eefe1110e00>

- The ~find_test~ function found the variable/functions in our python session (named 'ch6') whose name stated with 'test_'.

  The hexadecimal numbers in the output show where each function object is stored in memory.

  Having a running program find things in itself like this is called *introspection*, and is the key to many of the designs in upcoming chapters.

Combining introspection with the pass-fail-error pattern of the previous section gives us something that finds test functions, runs them, and summarizes their results:

#+name: def run_tests
#+begin_src python
def run_tests():
    results = {"pass": 0, "fail": 0, "error": 0}
    for (name, test) in globals().items():
        if not name.startswith("test_") or not callable(test):
            continue
        try:
            test()
            results["pass"] += 1
        except AssertionError:
            results["fail"] += 1
        except Exception:
            results["error"] += 1
    print(f"pass {results['pass']}")
    print(f"fail {results['fail']}")
    print(f"error {results['error']}")

#+end_src

In the above program we use ~callable~ to check if 'test' is actually a callable or not.

#+caption: Reason to use ~callable~
#+begin_src python
type(3)
# => <class 'int'>

def example():
    pass

type(example)
# => <class 'function'>

# Built-in functions have different type
type(len)
# => <class 'builtin_function_or_method'>

# Therefore, it is safert to use 'callable' to check if something can be called
callable(example)
# => True
callable(len)
# => True
#+end_src

** Questions
*** Looping over globals

*Q.* What happens if you run this code?
#+begin_src python :eval yes :session ch6-looping
for name in globals():
    print(name)
#+end_src

#+RESULTS:
: RuntimeError: dictionary changed size during iteration

*Q.* What happens if you run this code instead?
#+begin_src python :eval yes :session ch6-looping
name = None
for name in globals():
    print(name)
#+end_src

#+RESULTS:
#+begin_example
__name__
__doc__
__package__
__loader__
__spec__
__annotations__
__builtins__
tty
__PYTHON_EL_eval
__PYTHON_EL_eval_file
readline
__org_babel_python_format_value
__PYTHON_EL_native_completion_setup
name
#+end_example

*Q.* Why are the two different ?

*A.*

+ In the first example:

  When the =for= loop starts, =name= is not yet a variable in the global scope.

  As the loop iterates and assigns values to =name= (e.g., name = "__name__", name = "__doc__"), it implicitly /creates/ the =name= variable in the global scope.

  Creating a new global variable adds an entry to the ~globals()~ dictionary.
  Python disallows modifying a dictionary (like ~globals()~) while it is being iterated over, leading to a =RuntimeError=.

  - NOTE :: We get the same error EVEN IF we had used ~globals().items()~

+ In the second example:
  The line ~name = None~ /before/ the loop explicitly creates the =name= variable in the global scope.

  When the =for= loop begins, =name= already exists in the =globals()= dictionary. The loop then simply /reassigns/ the value of the /existing/ =name= variable in each iteration.

  This is not a modification of the dictionary's structure (no new key is added or removed during iteration), so no =RuntimeError= occurs.

*** Local Variables
Python has a function called ~locals~ that returns all the variables defined in the current /local scope/.
(local -- Referring to the current or innermost scope in a program.)



1. Predict what the code below will print before running it. When does the variable i first appear and is it still there in the final line of output?

2. Run the code and compare your prediction with its behavior.

#+begin_src python :eval yes :session ch6-locals
def show_locals(low, high):
    print(f"start: {locals()}")
    for i in range(low, high):
        print(f"loop {i}: {locals()}")
    print(f"end: {locals()}")

show_locals(1, 3)
#+end_src

#+RESULTS:
: start: {'low': 1, 'high': 3}
: loop 1: {'low': 1, 'high': 3, 'i': 1}
: loop 2: {'low': 1, 'high': 3, 'i': 2}
: end: {'low': 1, 'high': 3, 'i': 2}

The point here is that =i= still remains ever after the end of the for-loop.
This is because (I think) in python the innermost scope is the function scope, i.e. the for-loop doesn't have its own scope.

* Chapter 7: An Interpreter
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/interp/
:header-args:python: :session ch7 :results output :async yes :eval no
:header-args:sh: :session ch7-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       0a6eb5bf-e600-4902-9b35-011cc152a755
:END:
- Compilers and interpreters are just programs.
- Basic arithmetic operations are just functions that have special notation.
- Programs can be represented as trees, which can be stored as nested lists.

- Interpreters recursively _dispatch_ operations to functions that implement low-level steps.

- Programs store variables in /stacked/ dictionaries called *environments*.

- One way to evaluate a program's design is to ask how extensible it is.

#+caption: Interpreter concept map
[[file:images/Chapter_7:_Running_Tests/2025-08-25_10-57-23_screenshot.png]]

The central idea is that a program is just another kind of data.
Please see Appendix B for extra material related to these ideas.

** Theory
*** Intro

Most real programming languages have two parts:
1. a parser that translates the source code into a data structure,
2. and a runtime that executes the instructions in that data structure.

#+caption: Two ways to run Code
#+begin_quote
A compiler translates a program into runnable instructions before the program runs, while an interpreter generates instructions /on the fly/ as the program is running.

The differences between the two are BLURRY in practice:

for example, Python translates the instructions in a program into instructions as it loads files, but saves those instructions in .pyc files to save itself work the next time it runs the program.
#+end_quote

*** Expressions
:PROPERTIES:
:ID:       ee521d45-e4ef-4b47-8ead-b35cae5944e9
:END:

Let’s start by building something that can evaluate simple *expressions* such as 1+2 or abs(-3.5).

We represent each expression as a list with the name of the operation as the first item and the values to be operated on as the other items. If we have multiple operations, we use nested lists:

#+begin_src python
["add", 1, 2]            # 1 + 2
["abs", -3.5]            # abs(-3.5)
["add", ["abs", -5], 9]  # abs(-5) + 9
#+end_src

#+name: def do_add
#+begin_src python
def do_add(args):
    assert len(args) == 2
    left = do(args[0])
    right = do(args[1])
    return left + right
#+end_src

#+name: def do_abs
#+begin_src python
def do_abs(args):
    assert len(args) == 1
    val = do(args[0])
    return abs(val)
#+end_src

- NOTE :: that ~do_abs~ and ~do_add~ have the same signature. As with the unit testing functions in [[*Chapter 6: Running Tests][Chapter 6: Running Tests]], this allows us to call them interchangeably.

*Q.* So how does ~do~ work ?

*A.* It starts by checking if its input is an integer. If so, it returns that value right away because integers “evaluate” to themselves. Otherwise, ~do~ checks that its parameter is a list and then uses the first value in the list to decide what other function to call.

#+name: do
#+begin_src python
def do(expr):
    # Integers evaluate to themselves.
    if isinstance(expr, int):
        return expr

    # Lists trigger function calls.
    assert isinstance(expr, list)
    if expr[0] == "abs":
        return do_abs(expr[1:])
    if expr[0] == "add":
        return do_add(expr[1:])
    assert False, f"Unknown operation {expr[0]}"

#+end_src

This lookup-and-call process is called *dynamic dispatch*, since the program decides who to give work to on the fly.

It leads to a situation where ~do~ calls a function like ~do_add~, which in turn calls ~do~, which may then call ~do_add~ (or something other function) and so on.

- Dynamic dispatch ::
  To find a function or a property of an /object/ by name while a program is running.

  For example, instead of getting a specific property of an object using ~obj.name~, a program might use ~obj[someVariable]~, where someVariable could hold "name" or some other property name.

With all of this code in place, the main body of the program can read the file containing the instructions to execute, call do, and print the result:

#+begin_src python :tangle ./src/ch7/main.py :noweb yes
import sys
import json

<<def do_add>>

<<def do_abs>>

<<do>>

def main():
    assert len(sys.argv) == 2, "Usage: expr.py filename"
    with open(sys.argv[1], "r") as reader:
        program = json.load(reader)
    result = do(program)
    print(f"=> {result}")

if __name__ == "__main__":
    main()
#+end_src

#+begin_src python :tangle ./src/ch7/expr.tll
["add", ["abs", -3], 2]
#+end_src

#+begin_src sh
uv run ./src/ch7/main.py ./src/ch7/expr.tll
#+end_src

#+RESULTS:
: => 5

- Python reads expr.py, turns it into a data structure with operation identifiers and constants, and uses those operation identifiers to decide what functions to call.

  The functions inside Python are written in C and have been compiled to machine instructions, but the cycle of lookup and call _IS EXACTLY THE SAME_ as it is in our little interpreter.

*** Variables

Doing arithmetic on constants is a start, but our programs will be easier to read if we can define variables that give names to values.

We can add variables to our interpreter by passing around a dictionary containing all the variables seen so far.

Such a dictionary is sometimes called an *environment* because it is the setting in which expressions are evaluated; the dictionaries returned by the ~globals()~ and ~locals()~ functions introduced in Chapter 6 are both environments.

Let’s modify do_add, do_abs, do, and main to take an environment as an extra parameter and pass it on as needed:

#+name: def do; env, expr
#+begin_src python
def do(env, expr):
    # Integers evaluate to themselves.
    if isinstance(expr, int):
        return expr

    # Lists trigger function calls.
    assert isinstance(expr, list)
    if expr[0] == "abs":
        return do_abs(env, expr[1:])
    if expr[0] == "add":
        return do_add(env, expr[1:])
    if expr[0] == "get":
        return do_get(env, expr[1:])
    if expr[0] == "seq":
        return do_seq(env, expr[1:])
    if expr[0] == "set":
        return do_set(env, expr[1:])
    assert False, f"Unknown operation {expr[0]}"
#+end_src

#+name: do this and that
#+begin_src python
def do_add(env, args):
    assert len(args) == 2
    left = do(env, args[0])
    right = do(env, args[1])
    return left + right

def do_abs(env, args):
    assert len(args) == 1
    val = do(env, args[0])
    return abs(val)

# Looking up variables when we need their values is straightforward. We check
# that we have a variable name and that the name is in the environment, then
# return the stored value:
def do_get(env, args):
    assert len(args) == 1
    assert isinstance(args[0], str)
    assert args[0] in env, f"Unknown variable {args[0]}"
    return env[args[0]]

# To define a new variable or change an existing one, we evaluate an expression
# and store its value in the environment:
def do_set(env, args):
    assert len(args) == 2
    assert isinstance(args[0], str)
    value = do(env, args[1])
    env[args[0]] = value
    return value

# We need to add one more function to make this all work. Our programs no longer
# consist of a single expression; instead, we may have several expressions that
# set variables’ values and then use them in calculations. To handle this, we
# add a function do_seq that runs a sequence of expressions one by one. This
# function is our first piece of control flow: rather than calculating a value
# itself, it controls when and how other expressions are evaluated. Its
# implementation is:
def do_seq(env, args):
    assert len(args) > 0
    for item in args:
        result = do(env, item)
    return result

#+end_src

#+begin_src python :tangle ./src/ch7/main2.py :noweb yes
import sys
import json

<<do this and that>>

<<def do; env, expr>>

def main():
    assert len(sys.argv) == 2, "Usage: expr.py filename"
    with open(sys.argv[1], "r") as reader:
        program = json.load(reader)
    env = {} # initialize the environment
    result = do(env, program)
    print(f"=> {result}")

if __name__ == "__main__":
    main()

#+end_src

#+begin_src python :tangle ./src/ch7/expr2.tll
[
    "seq",
    ["set", "alpha", 1],
    ["set", "beta", 2],
    ["add", ["get", "alpha"], ["get", "beta"]]
]
#+end_src

#+begin_src sh
uv run ./src/ch7/main2.py ./src/ch7/expr2.tll
#+end_src

#+RESULTS:
: => 3

#+caption: Everything is an expression
[[file:images/Chapter_7:_Running_Tests/2025-08-25_11-29-15_screenshot.png]]

*** Introspection
:PROPERTIES:
:ID:       122a8a24-1485-43e1-9e20-ce9512e9f212
:END:

In [[def do; env, expr]], the sequence of =if= statements that decide what function to call is becoming unwieldy.

We can replace this by using *introspection* to create a lookup table that stores every function whose name starts with 'do_'

- Introspection/Reflection ::
  To inspect the properties of a running program in a generic way.
  Reflection relies on the fact that a program is just another data structure.

  #+caption: Dynamically-generated function lookup table
  [[file:images/Chapter_7:_Running_Tests/2025-08-25_13-32-29_screenshot.png]]

We wanna map functions like 'do_operationName' to the name 'operationName' so that we can get rid of our =if= statements.

#+begin_src python :tangle ./src/ch7/main3.py :noweb yes
import sys
import json

<<do this and that>>

OPS = {
    name.replace('do_', ''): func
    for name, func in globals().items()
    if name.startswith('do_') and callable(func)
}

def do(env, expr):
    # Integers evaluate to themselves.
    if isinstance(expr, int):
        return expr

     # Lists trigger function calls.
    assert isinstance(expr, list)
    assert expr[0] in OPS, f"Unknown operation {expr[0]}"
    func = OPS[expr[0]]
    return func(env, expr[1:])

def main():
    assert len(sys.argv) == 2, "Usage: expr.py filename"
    with open(sys.argv[1], "r") as reader:
        program = json.load(reader)
    env = {} # initialize the environment
    result = do(env, program)
    print(f"=> {result}")

if __name__ == "__main__":
    main()
#+end_src

As with unit test functions in [[*Chapter 6: Running Tests][Chapter 6: Running Tests]] , the ~do_*~ functions MUST HAVE exactly the same signature so that we can call any of them with an environment and a list of arguments _without knowing exactly which function we’re calling_.

And as with finding tests, introspection is more reliable than a hand-written lookup table BUT is harder to understand.

#+begin_src sh
uv run ./src/ch7/main3.py ./src/ch7/expr2.tll
#+end_src

#+RESULTS:
: => 3

* Chapter 8: Functions and Closures
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/func/
:header-args:python: :session ch8 :results output :async yes :eval no
:header-args:sh: :session ch8-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       73897404-84eb-4888-97b6-1ae9846fe82e
:END:

- When we define a function, our programming system _saves instructions for later use_.
- Since functions are just data, we can separate creation from naming.

- Most programming languages use *eager evaluation*, in which arguments are evaluated before a function is called.

- Programming languages can also use lazy evaluation, in which expressions are passed to functions for just-in-time evaluation.

- Every call to a function creates a new stack frame on the call stack.

- When a function looks up variables it checks its own stack frame and the global frame.

- A *closure* stores the variables referenced in a particular scope.

#+caption: Concept Map
[[file:images/Chapter_8:_Functions_and_Closures/2025-08-25_14-31-09_screenshot.png]]

** Theory
*** Intro

One way to evaluate the design of a piece of software is to ask how extensible it is, i.e., how easily we can add or change things.

The answer for the interpreter of [[*Chapter 7: An Interpreter][Chapter 7: An Interpreter]] is “pretty easily” but the answer for the little language it interprets is “not at all”, because users cannot define new operations in the little language itself.

We need to give them a way to define and call functions.

Doing this will take less than 60 lines of code, and once we understand how definition works, we will be able to understand how an advanced feature of most modern programming languages works as well.

*** Definition and Storage

For the following function:

#+begin_src python
def same(num):
    return num
#+end_src

Since a function is just another kind of object, we can define it on its own without naming it:

#+caption: [func, args, body]
#+begin_src python
["func", ["num"], ["get", "num"]]
#+end_src

To save the function for later use, we simply assign it to a name as we would assign any other value:

#+begin_src python
["set", "same", ["func", ["num"], ["get", "num"]]]
#+end_src

*** Calling Functions
In Python, we would call this function as ~same(3)~.

Our little language requires us to specify an operator explicitly, so we write the call as:

#+begin_src python
["call", "same", 3]
#+end_src

To make =call= work the way most programmers expect, we need to implement *scope* so that the parameters and variables used in a function aren’t confused with those defined outside it.

In other words, we need to prevent name collision.

When a function is /called/ with one or more expressions as arguments, we will:

1. Evaluate all of these expressions.
2. Look up the function.
3. Create a new environment from the function’s parameter names and the expressions’ values.
4. Call ~do~ to run the function’s action and capture the result.
5. Discard the environment created in Step 3.
6. Return the function’s result.

#+caption: Eager and Lazy.
#+begin_quote

Evaluating a function’s arguments before we run it is called *eager evaluation*.

We could instead use *lazy evaluation*, in which case we would pass the argument sub-lists into the function and let it evaluate them when it needed their values.

Python and most other languages are eager, but a handful of languages, such as R, are lazy.

It’s a bit more work, but it allows the function to inspect the expressions it has been called with and to decide how to handle them.

To make this work, the environment must be a /list of dictionaries/ instead of a single dictionary.

This list is the *call stack* of our program, and each dictionary in it is usually called a *stack frame*. When a function wants the value associated with a name, we look through the list from the most recent dictionary to the oldest.

#+end_quote

#+caption: Scoping Rules
#+begin_quote

Searching through all active stack frames for a variable is called *dynamic scoping*.

In contrast, most programming languages used *lexical scoping*, which figures out what a variable name refers to based on the structure of the program text.

The former is easier to implement (which is why we’ve chosen it); the latter is easier to understand, particularly in large programs. [Nystrom2021] has an excellent step-by-step explanation of how to build lexical scoping.

#+end_quote

The completed implementation of function definition is:

#+name: def do_func
#+begin_src python
def do_func(env, args):
    assert len(args) == 2
    params = args[0]
    body = args[1]
    return ['func', params, body]

# NOTE: How the above function just checks that function has the correct shape
# and just returns the same value as earlier.

# This is what we mean when we say that a function:
# saves instructions for later use.
#+end_src

and the completed implementation of function call is:

#+name: def do_call
#+begin_src python
def do_call(env, args):
    # set up the call
    assert len(args) >= 1
    name = args[0]
    arguments = [do(env, a) for a in args[1:]]

    # find the function
    func = do_get(env, [name])
    # NOTE :: In the above, if I wrote list(name), then
    # we would get ['a', 'b', 'c'] for the name='abc' !!
    assert isinstance(func, list) and (func[0] == 'func')
    params, body = func[1], func[2]
    assert len(arguments) == len(params)

    # Run in new environment
    env.append(dict(zip(params, arguments))) # Noice
    result = do(env, body)
    env.pop()

    # Report
    return result
#+end_src

#+begin_src python :tangle ./src/ch8/test.tll
["seq",
  ["set", "double",
    ["func", ["num"],
      ["add", ["get", "num"], ["get", "num"]]
    ]
  ],
  ["set", "a", 1],
  ["repeat", 4, ["seq",
    ["set", "a", ["call", "double", ["get", "a"]]],
    ["print", ["get", "a"]]
  ]]
]
#+end_src

We also need to define a ~do_repeat~ and ~do_print~ for our test case:

#+name: do_repeat and do_print
#+begin_src python
def do_repeat(env, args):
    # ['repeat', times, body]
    assert len(args) == 2

    times = do(env, args[0])
    body = args[1]

    for _ in range(times):
        do(env, body)

def do_print(env, args):
    # ['print', thing]
    assert len(args) == 1
    value = do(env, args[0])
    print(value)
#+end_src

We also need to redefine ~do_get~, ~do_set~, our initial environment etc.

#+name: redefined do_blah
#+caption: changed do_get, do_set
#+begin_src python
#from pprint import pprint

def do_add(env, args):
    assert len(args) == 2
    left = do(env, args[0])
    right = do(env, args[1])
    return left + right

def do_abs(env, args):
    assert len(args) == 1
    val = do(env, args[0])
    return abs(val)

# Changed !
def do_get(env, args):
    # pprint('do_get')
    # pprint(f'env: {env}')
    # pprint(f'args: {args}')
    assert len(args) == 1
    assert isinstance(args[0], str)
    name = args[0]
    for d in reversed(env):
        if name in d:
            return d[name]
    raise Exception(f'nothing defined with name: {name}')

# Changed !
def do_set(env, args):
    assert len(args) == 2
    assert isinstance(args[0], str)
    value = do(env, args[1])
    env[-1][args[0]] = value
    return value

def do_seq(env, args):
    assert len(args) > 0
    for item in args:
        result = do(env, item)
    return result

#+end_src

#+caption: environment is now a list of dicts
#+begin_src python :tangle ./src/ch8/main.py :noweb yes
import sys
import json

<<redefined do_blah>>

<<def do_func>>

<<def do_call>>

<<do_repeat and do_print>>

OPS = {
    name.replace('do_', ''): func
    for name, func in globals().items()
    if name.startswith('do_') and callable(func)
}

def do(env, expr):
    # Integers evaluate to themselves.
    if isinstance(expr, int):
        return expr

     # Lists trigger function calls.
    assert isinstance(expr, list)
    assert expr[0] in OPS, f"Unknown operation {expr[0]}"
    func = OPS[expr[0]]
    # pprint(f'Calling func: {expr[0]}')
    # pprint(f'with args: {expr[1:]}')
    return func(env, expr[1:])

def main():
    assert len(sys.argv) == 2, "Usage: expr.py filename"
    with open(sys.argv[1], "r") as reader:
        program = json.load(reader)
    # NOTE: list(dict()) => []
    env = [dict()] # Changed !

    result = do(env, program)
    print(f"=> {result}")

if __name__ == "__main__":
    main()
#+end_src


#+begin_src sh
uv run ./src/ch8/main.py ./src/ch8/test.tll
#+end_src

#+RESULTS:
: 2
: 4
: 8
: 16
: => None

- NOTE :: Once again, Python and other languages do more or less what we’ve done here.

  - When we define a function, the interpreter saves the instructions in a lookup table.

  - When we call a function at runtime, the interpreter finds the function in the table, creates a new stack frame, executes the instructions in the function, and pops the frame off the stack.

*** Closures
:PROPERTIES:
:ID:       eae5e10f-5a58-4670-b02c-818121f044e4
:END:

#+begin_src python :eval yes
def make_hidden(thing):
    def _inner():
        return thing
    return _inner

has_secret = make_hidden(1 + 2)
print("hidden thing is", has_secret())
#+end_src

#+RESULTS:
: hidden thing is 3

In the above code, the inner function still has access to the value of thing, but nothing else in the program does.

A computer scientist would say that the inner function /captures/ the variables in the enclosing function to create a *closure*.

- Closure ::
  A record that stores a /function/ _AND_ /its environment/ so that variables that were in scope when the function was defined can still be accessed from within the function even if they are no longer visible to other parts of the program.

- One common use of closures is to turn a function that needs many arguments into one that needs fewer, i.e., to create a function /now/ that remembers some values it’s supposed to use /later/.

- Closures are also another way to implement objects.

  Instead of building a dictionary ourselves as we did in [[*Chapter 2: Objects and Classes][Chapter 2: Objects and Classes]], we use the one that Python creates behind the scenes to implement a closure.

  In the code below, for example, the function make_object creates a dictionary containing two functions:

  #+begin_src python :eval yes
  def make_object(initial_value):
      private = {"value": initial_value}

      def getter():
          return private["value"]

      def setter(new_value):
          private["value"] = new_value

      return {"get": getter, "set": setter}

  object = make_object(00)
  print("initial value", object["get"]())
  object["set"](99)
  print("object now contains", object["get"]())

  #+end_src

  #+RESULTS:
  : initial value 0
  : object now contains 99

#+caption: Implementing objects using closures.
[[file:images/Chapter_8:_Functions_and_Closures/2025-08-25_17-34-08_screenshot.png]]

When this code runs, Python creates a closure that is shared by the two functions (Figure 8.2).

The closure has a key "private"; there is nothing special about this name, but nothing in the program can see the data in the closure except the two functions.

We could add more keys to this dictionary to create more complex objects and build an entire system of objects and classes this way.

* Chapter 9: Protocols
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/protocols/
:header-args:python: :session ch9 :results output :async yes :eval no
:header-args:sh: :session ch9-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       9c0cb28c-9195-436e-b67f-35a07fd53eae
:END:

- Temporarily replacing functions with mock objects can simplify testing.
- Mock objects can record their calls and/or return variable results.

- Python defines protocols so that code can be triggered by keywords in the language.
- Use the /context manager protocol/ to ensure cleanup operations always execute.

- Use decorators to wrap functions after defining them.
- Use closures to create decorators that take extra parameters.

- Use the iterator protocol to make objects work with for loops.

#+caption: Concept map
[[file:images/Chapter_9:_Protocols/2025-08-26_13-16-42_screenshot.png]]

In this chapter, we will look at how Python allows users to tell it to do things at specific moments.

** Theory
*** Mock objects

#+caption: Temporary replacement
#+begin_src python
import time

def elapsed(since):
    return time.time() - since

def mock_time():
    return 200

def test_elapsed():
    time.time = mock_time
    assert elapsed(50) == 150
#+end_src

Temporary replacements like this are called *mock objects* because we usually use objects even if the thing we’re replacing is a function.

- mock object ::
  A simplified replacement for part of a program whose behavior is easy to control and predict.

  Mock objects are used in unit tests to simulate databases, web services, and other complex systems.

- We can do this because Python lets us create objects that can be “called” just like functions.

  If an object obj has a ~__call__~ method, then ~obj(…)~ is automatically turned into =obj.__call__(…)= just as ~a == b~ is automatically turned into =a.__eq__(b)=

  #+caption: example of __call__
  #+begin_src python :eval yes
  class Adder:
      def __init__(self, value):
          self.value = value

      def __call__(self, arg):
          return arg + self.value

  add_3 = Adder(3)
  result = add_3(8)
  print(f"add_3(8): {result}")
  #+end_src

  #+RESULTS:
  : add_3(8): 11

#+caption: Defining a resuable mock object class
#+name: class Fake
#+begin_src python
class Fake:
    def __init__(self, func=None, value=None):
        """
        the fake value is generated using 'func' or 'value'
        """
        self.calls = []
        self.func = func
        self.value = value

    def __call__(self, *args, **kwargs):
        self.calls.append([args, kwargs])
        if self.func is not None:
            return self.func(*args, **kwargs)
        return self.value
#+end_src

The above is a reusable mock object class that:

1. defines a ~__call__~ method so that instances can be called like functions;

2. declares the parameters of that method to be ~*args~ and ~**kwargs~ so that it can be called with any number of regular or keyword arguments;

3. stores those arguments so we can see how the replaced function was called; and

4. returns either a fixed value or a value produced by a user-defined function.

For convenience, let’s also define a function that replaces some function we’ve already defined with an instance of our =Fake= class:

#+begin_src python
def fakeit(name, func=None, value=None):
    assert name in globals()
    fake = Fake(func, value)
    globals()[name] = fake
    return fake

def adder(a, b):
    return a + b

def test_with_real_function():
    assert adder(2, 3) == 5

def test_with_fixed_return_value():
    fakeit("adder", value=99)
    assert adder(2, 3) == 99

#+end_src

The problem with ~fakeit~ is that using mock objects should be a temporary thing.
But, when we use ~fakeit~ we reassign 'name' to the fake function, but don't reassign it to the original function !

*** Protocols

A protocol is a rule that specifies how programs can tell Python to do specific things at specific moments.
- ~__init__~
- ~__call__~
- context manager ::
    An object that automatically executes some operations at the start of a code block and some other operations at the end of the block.

What we want for managing mock objects is a *context manager* that replaces the real function with our mock at the start of a block of code and then puts the original back at the end.

The protocol for this relies on two methods called ~__enter__~ and ~__exit__~. If the class is called =C=, then when Python executes a with block like this:

#+begin_src python
with C(..args..) as name:
    ...do things...
#+end_src

does the following:

1. Call C’s constructor to create an object that it associates with the code block.
2. Call that object’s ~__enter__~ method and assign the result to the variable =name=.

   #+begin_src python
   def __enter__(self):
       # __enter__ doesn't take any arguments apart from self.
       # Anything it needs must be provided via the object’s constructor.
       # ...
       # ..
       # The value returned by __enter__ (can be 'self') is assigned to the
       # variable 'name'
       return someValue
   #+end_src

3. Run the code inside the =with= block.

4. Call ~name.__exit__()~ when the block finishes.

   #+begin_src python
   def __exit__(self, exc_type, exc_value, exc_traceback):
       # __exit__ will always be called with three values that tell it whether an
       # exception occurred, and if so, what the exception was.
       #
       # do stuff
   #+end_src

#+caption: Mock object context manager
#+name: class ContextFake
#+begin_src python :noweb yes
<<class Fake>>

class ContextFake(Fake):
    def __init__(self, name, func=None, value=None):
        super().__init__(func, value)
        self.name = name
        self.original = None

    def __enter__(self):
        assert self.name in globals()
        self.original = globals()[self.name]
        globals()[self.name] = self  # OH, we use the __call__ method of 'Fake'
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        globals()[self.name] = self.original
#+end_src

#+caption: example usage
#+begin_src python :noweb yes :eval yes
<<class ContextFake>>

def subber(a, b):
    return a - b

def check_no_lasting_effects():
    assert subber(2,3) == -1
    with ContextFake('subber', value=1234) as fake:
        assert subber(2,3) == 1234
        assert len(fake.calls) == 1
        print(f'Inside: subber(2,3) = {subber(2,3)}')
    print(f'Outside: subber(2,3) = {subber(2,3)}')
    assert subber(2,3) == -1

check_no_lasting_effects()
#+end_src

#+RESULTS:
: Inside: subber(2,3) = 1234
: Outside: subber(2,3) = -1

Context managers can’t prevent people from making mistakes, but they make it easier for people to do the right thing.

They are also an example of how programming languages often evolve: eventually, if enough people are doing something the same way in enough places, support for that way of doing things is added to the language.

*** Decorators
- decorator ::
  A function A that can be applied to another function B when function B is being defined to change its behavior in some way.

A *decorator* allows us to wrap one function with another.

#+begin_src python :eval yes
def wrap(func):
    def new_func(*args):
        print('before call')
        func(*args)
        print('after call')
    return new_func

@wrap
def original(message):
    print(f'original: {message}')

original('example')
#+end_src

#+RESULTS:
: before call
: original: example
: after call

In the above code ~@wrap~ makes it so that
#+begin_src python
original = wrap(original)
# therefore, 'original' now refers to 'new_func'
#+end_src

If we want to pass arguments at the time we apply the decorator, though, it seems like we’re stuck: a Python decorator _must take_ exactly one argument, which must be the function we want to decorate.

The solution is to define a function inside a function /inside yet another function/ to create a closure that captures the arguments:

#+begin_src python :eval yes
def wrap(*args):                  # function returning a decorator
    def _decorate(func):          # the decorator Python will apply
        def _new_func(*_args):        # the wrapped function
            print(f"++ {[*args]}")  # 'label' is visible because
            func(*_args)           # …it's captured in the closure
            print(f"-- {[*args]}")  # …of '_decorate'
        return _new_func
    return _decorate

@wrap("arg1", "arg2")                 # call 'wrap' to get a decorator
def original(message):            # decorator applied here
    print(f"original: {message}")

original("example")
#+end_src

#+RESULTS:
: ++ ['arg1', 'arg2']
: original: example
: -- ['arg1', 'arg2']

*** Iterators

As a last example of how protocols work, consider the =for= loop. The statement ~for thing in collection~ assigns items from ~collection~ to the variable ~thing~ one at a time.

- iterator ::
  A function or object that produces each value from a collection in turn for processing.

- Iterator pattern :: A design pattern that uses iterators to hide the differences between different kinds of data structures so that everything can be processed using loops.

Python implements this using a two-part /iterator/ protocol, which is a version of the *Iterator design* pattern:

1. If an object has an ~__iter__~ method, that method is called to create an iterator object.

2. That iterator object must have a ~__next__~ method, which must return a value each time it is called.
   When there are no more values to return, it must raise a =StopIteration= exception.


For example, suppose we have a class that stores a list of strings and we want to return the characters from the strings in order.

#+name: class NaiveIterator
#+begin_src python
class NaiveIterator:
    def __init__(self, text):
        self._text = text[:]

    def __iter__(self):
        self._row, self._col = 0, -1
        return self

    def __next__(self):
        # We want to handle cases where,
        # text = ['a', '', '', b]
        # text = ['', '', 'a']
        # text = ['', '', '']
        #
        # that is why we start at (0, -1)
        self._advance() # 0,-1 -> 0,0

        return self._text[self._row][self._col]

    def _advance(self):
        # check if row is valid
        if self._row < len(self._text):
            n = len(self._text[self._row])
            self._col += 1
            if self._col >= n:
                self._row += 1
                self._col = 0
        else:
            raise StopIteration

        # check if (row, col) is valid
        if not self._is_valid():
            # try again
            self._advance()

    def _is_valid(self) -> bool:
        """
        Returns boolean indicating whether our row and col
        are at a valid position in text.
        """
        if self._row < len(self._text):
            item = self._text[self._row]
            if self._col < len(item):
                return True
        return False
#+end_src

#+begin_src python :noweb yes :eval yes
<<class NaiveIterator>>
from typing import Iterable

def gather(buffer: Iterable):
    result = ""
    for char in buffer:
        result += char
    return result

def test_naive_buffer():
    buffer = NaiveIterator(["ab", "c"])
    result = gather(buffer)
    print(result == 'abc', f';result: {result}')

def test_naive_buffer_empty_string():
    buffer = NaiveIterator(['a', '', '', 'b'])
    result = gather(buffer)
    print(result == 'ab', f';result: {result}')

    buffer = NaiveIterator(['', '', 'a'])
    result = gather(buffer)
    print(result == 'a', f';result: {result}')

    buffer = NaiveIterator(['', '', ''])
    result = gather(buffer)
    print(result == '', f';result: {result}')

def test_naive_buffer_nested_loop():
    buffer = NaiveIterator(["a", "b"])
    result = ""
    for outer in buffer:
        for inner in buffer:
            result += inner
    print(result == 'abab', f';result: {result}')

test_naive_buffer()
test_naive_buffer_empty_string()
test_naive_buffer_nested_loop()
#+end_src

#+RESULTS:
: True ;result: abc
: True ;result: ab
: True ;result: a
: True ;result:
: False ;result: ab

In our first attempt, each object is its own iterator, i.e., each object keeps track of what value to return next when looping.

- ~NaiveIterator~ fails when we use a nested loop.

  The problem is that we only have one pair of variables (the ~_row~ and ~_col~ attributes of the buffer) to store the current location, but two loops trying to use them.

What we need to do instead is create a separate object for each loop to use,
i.e each time the ~__iter__~ should return a new object:

#+name: class BetterIterator
#+begin_src python
class BetterIterator:
    def __init__(self, text):
        self._text = text[:]

    def __iter__(self):
        return BetterCursor(self._text)

class BetterCursor:
    def __init__(self, text):
        self._text = text
        self._row = 0
        self._col = -1

    def __next__(self):
        # We want to handle cases where,
        # text = ['a', '', '', b]
        # text = ['', '', 'a']
        # text = ['', '', '']
        #
        # that is why we start at (0, -1)
        self._advance() # 0,-1 -> 0,0

        return self._text[self._row][self._col]

    def _advance(self):
        # check if row is valid
        if self._row < len(self._text):
            n = len(self._text[self._row])
            self._col += 1
            if self._col >= n:
                self._row += 1
                self._col = 0
        else:
            raise StopIteration

        # check if (row, col) is valid
        if not self._is_valid():
            # try again
            self._advance()

    def _is_valid(self) -> bool:
        """
        Returns boolean indicating whether our row and col
        are at a valid position in text.
        """
        if self._row < len(self._text):
            item = self._text[self._row]
            if self._col < len(item):
                return True
        return False
#+end_src


- NOTE :: The ~BetterIterator~ doesn't have a ~__next__~ method, while ~BetterCursor~ doesn't have an ~__iter__~ method.

#+begin_src python :noweb yes :eval yes
<<class BetterIterator>>
from typing import Iterable

def gather(buffer: Iterable):
    result = ""
    for char in buffer:
        result += char
    return result

def test_naive_buffer():
    buffer = BetterIterator(["ab", "c"])
    result = gather(buffer)
    print(result == 'abc', f';result: {result}')

def test_naive_buffer_empty_string():
    buffer = BetterIterator(['a', '', '', 'b'])
    result = gather(buffer)
    print(result == 'ab', f';result: {result}')

    buffer = BetterIterator(['', '', 'a'])
    result = gather(buffer)
    print(result == 'a', f';result: {result}')

    buffer = BetterIterator(['', '', ''])
    result = gather(buffer)
    print(result == '', f';result: {result}')

def test_naive_buffer_nested_loop():
    buffer = BetterIterator(["a", "b"])
    result = ""
    for outer in buffer:
        for inner in buffer:
            result += inner
    print(result == 'abab', f';result: {result}')

test_naive_buffer()
test_naive_buffer_empty_string()
test_naive_buffer_nested_loop()
#+end_src

#+RESULTS:
: True ;result: abc
: True ;result: ab
: True ;result: a
: True ;result:
: True ;result: abab

* Chapter 10: A File Archiver
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/archive/
:header-args:python: :session ch10 :results output :async yes :eval no
:header-args:sh: :session ch10-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       b3ed8b6c-796e-4486-ad01-c920cf49c7f3
:END:

- Version control tools use hashing to uniquely identify each saved file.
- Each snapshot of a set of files is recorded in a *manifest*.

- Using a /mock filesystem/ for testing is safer and faster than using the real thing.

- Operations involving multiple files may suffer from /race conditions/.

- Use a base class to specify what a component must be able to do and derive child classes to implement those operations.

#+caption: Concept map for hashing-based file backup
[[file:images/Chapter_10:_Protocols/2025-08-29_14-45-25_screenshot.png]]

A *version control system* like Git keeps track of changes to files so that we can see what we’ve changed, recover old versions, and merge our changes with those made by other people.

- The CORE of a modern version control tool is a way to archive files that:

  1. records which versions of which files existed at the same time, so that we can go back to a consistent previous state, and

  2. stores any particular version of a file only once, so that we don’t waste disk space.

This chapter builds a tool that does both tasks.

- It won’t create and merge branches; if you would like to see how that works, please see [[http://gitlet.maryrosecook.com/][Mary Rose Cook’s Gitlet]] or Thibault Polge’s [[https://wyag.thb.lt/][Write yourself a Git]] ( TODO: looks awesome :)

** Theory
*** Setup

#+begin_src sh
mkdir -p ./src/ch10/sample_dir
mkdir -p ./src/ch10/sample_dir/sub_dir

echo aaa > ./src/ch10/sample_dir/a.txt
echo bbb > ./src/ch10/sample_dir/b.txt
echo ccc > ./src/ch10/sample_dir/sub_dir/c.txt

tree --charset ascii ./src/ch10/sample_dir/
#+end_src

#+RESULTS:
: ./src/ch10/sample_dir/
: |-- a.txt
: |-- b.txt
: `-- sub_dir
:     `-- c.txt
:
: 2 directories, 3 files

*** Saving Files
:PROPERTIES:
:ID:       34f27697-cb19-4ff6-949d-3aa34e92c9b2
:END:

#+caption: Organization of backup file storage
[[file:images/Chapter_10:_Protocols/2025-08-29_15-11-22_screenshot.png]]


- Many files only change occasionally after they’re created, or not at all.

  It would be wasteful for a version control system to make copies each time the user saved a snapshot of a project, so instead we will copy each unique file to something like abcd1234.bck, where abcd1234 is the hash of the file’s contents.

- Each snapshot (a csv file named using the current timestamp) consist of a list of (filename, hash-value)

  In that snapshot, that filename is associated with some 'hash-value' (made from that file's contents) and we will find the file associated with that hash at 'hash-value.bck'


The first step is to find all the files in or below a given directory that we need to save.
Python's [[https://docs.python.org/3/library/glob.html][glob]] module can do this for us.

#+name: hash_all
#+begin_src python :tangle ./src/ch10/hash_all.py
from glob import glob
from hashlib import sha256
from pathlib import Path

HASH_LEN=16

def hash_all(root):
    result = []
    for name in glob("**/*.*", root_dir=root, recursive=True):
        full_name = Path(root, name)
        with open(full_name, "rb") as reader:
            data = reader.read()
            # we are truning to [:16] for readable
            hash_code = sha256(data).hexdigest()[:HASH_LEN]
            result.append((name, hash_code))
    return result

#+end_src

Notice that we’re truncating the hash code of each file to just 16 hexadecimal digits.

This greatly increases the odds of collision, so real version control systems don’t do this, but it makes our program’s output easier to show on screen.

For example:

#+begin_src python :noweb yes :eval yes
from pprint import pprint

<<hash_all>>

pprint(hash_all('./src/ch10/sample_dir/'))
#+end_src

#+RESULTS:
: [('a.txt', '17e682f060b5f8e4'),
:  ('b.txt', '3cf9a1a81f6bdeaf'),
:  ('sub_dir/c.txt', '5695d82a086b6779')]

*** Testing
:PROPERTIES:
:ID:       b5b19ec1-7687-46be-812b-a896df172f27
:END:

Before we go any further we need to figure out how we’re going to test our code.

+ The obvious approach :: is to create directories and sub-directories containing some files we can use as fixtures.

  - However :: we are going to change or delete those files as we back things up and restore them.

    To make sure early tests don’t contaminate later ones, we would have to recreate those files and directories after each test.


+ Better approach :: is to use a mock object instead of the real filesystem.

  The [[https://pytest-pyfakefs.readthedocs.io/][pyfakefs]] module replaces key functions like open with functions that behave the same way but act on “files” stored /in memory/.

  Using it prevents our tests from accidentally disturbing the filesystem; it also makes tests much faster since in-memory operations are thousands of times faster than ones that touch the disk.

#+caption: Using a mock filesystem to simplify testing
[[file:images/Chapter_10:_Protocols/2025-08-30_11-41-42_screenshot.png]]

If we import =pyfakefs=, we automatically get a fixture called ~fs~ that we can use to create files. We tell =pytest= we want to use this fixture by passing it as an argument to our testing function:

#+begin_src python :tangle ./src/ch10/test_mock_fs.py
import pyfakefs
from pathlib import Path

# Here 'fs' is a pytest fixture
def test_simple_example(fs):
    sentence = "this file contains one sentence."
    with open('alpha.txt', 'w') as writer:
        writer.write(sentence)
    assert Path('alpha.txt').exists()
    with open('alpha.txt', 'r') as reader:
        assert reader.read() == sentence
#+end_src

#+begin_src sh
uvx --with pyfakefs pytest ./src/ch10/test_mock_fs.py
#+end_src

#+RESULTS:
: =============================== test session starts ================================
: platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: plugins: pyfakefs-5.9.3
: collected 1 item
:
: src/ch10/test_mock_fs.py .                                                   [100%]
:
: ================================ 1 passed in 0.03s =================================

We can use ~fs~ to create more complicated fixtures of our own with multiple directories and files:

#+begin_src python :tangle ./src/ch10/test_mock_tree.py
from pathlib import Path
import pytest

@pytest.fixture
def our_fs(fs):
    fs.create_file('a.txt', contents='aaa')
    fs.create_file("b.txt", contents="bbb")
    fs.create_file("sub_dir/c.txt", contents="ccc")

def test_nested_example(our_fs):
    assert Path("a.txt").exists()
    assert Path("b.txt").exists()
    assert Path("sub_dir/c.txt").exists()

def test_deletion_example(our_fs):
    assert Path("a.txt").exists()
    Path("a.txt").unlink()
    assert not Path("a.txt").exists()
#+end_src

and then test that [[hash_all]] finds all the files:

#+begin_src python :tangle ./src/ch10/test_hash_all.py
import pytest

from hash_all import hash_all, HASH_LEN

@pytest.fixture
def our_fs(fs):
    fs.create_file("a.txt", contents="aaa")
    fs.create_file("b.txt", contents="bbb")
    fs.create_file("sub_dir/c.txt", contents="ccc")

def test_hashing(our_fs):
    result = hash_all(".")
    expected = {"a.txt", "b.txt", "sub_dir/c.txt"}
    assert {r[0] for r in result} == expected
    assert all(len(r[1]) == HASH_LEN for r in result)
#+end_src

and that hashes change when files change:

#+begin_src python :tangle ./src/ch10/test_hash_all.py

def test_change(our_fs):
    original = hash_all(".")
    original = [entry for entry in original if entry[0] == "a.txt"][0]
    with open("a.txt", "w") as writer:
        writer.write("this is new content for a.txt")
    changed = hash_all(".")
    changed = [entry for entry in changed if entry[0] == "a.txt"][0]
    assert original != changed
#+end_src


#+begin_src sh
uvx --with pyfakefs pytest ./src/ch10/
#+end_src

#+RESULTS:
#+begin_example
=============================== test session starts ================================
platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
rootdir: /home/nabeel/Documents/public/books/Software Design by Example
plugins: pyfakefs-5.9.3
collected 5 items

src/ch10/test_hash_all.py ..                                                 [ 40%]
src/ch10/test_mock_fs.py .                                                   [ 60%]
src/ch10/test_mock_tree.py ..                                                [100%]

================================ 5 passed in 0.05s =================================
#+end_example

*** Tracking Backups

The second part of our backup tool keeps track of which files have and haven’t been backed up already.

It stores backups in a directory that contains files like abcd1234.bck (the hash followed by .bck) and creates a manifest that describes the content of each snapshot.

A real system would support remote storage as well so that losing one hard drive wouldn’t mean losing all our work, so we need to design our system with multiple back ends in mind.

For now, we will store manifests in CSV files named ssssssssss.csv, where ssssssssss is the UTC timestamp of the backup’s creation.

#+caption: Time of Check / Time of Use
#+begin_quote
Our naming convention for manifests will fail if we try to create two or more backups in the same second.

This *might seem unlikely*, BUT many faults and security holes are the result of programmers ASSUMING things weren’t going to happen.

We could try to avoid this problem by using a two-part naming scheme ssssssss-a.csv, ssssssss-b.csv, and so on, but this leads to a race condition called time of check/time of use.

- time of check - time of use ::
  A race condition in which a process checks the state of something and then operates on it, but some other process might alter that state between the check and the operation.

If two users run the backup tool at the same time, they will both see that there isn’t a file (yet) with the current timestamp, so they will both try to create the first one.

Ensuring that multi-file updates are /atomic operations/ (i.e., that they always appear to be a single indivisible step) is a hard problem; file locking is a common approach, but complete solutions are out of the scope of this book.

- file locking ::
  The act of restricting updates to a file, or its deletion, so that operations on it appear atomic.
#+end_quote

This function creates a backup -- or rather, it will once we fill in all the functions it depends on:

#+begin_src python :tangle ./src/ch10/backup.py
import csv
import shutil
import time
from pathlib import Path
from hash_all import hash_all

def backup(source_dir, backup_dir):
    manifest = hash_all(source_dir)
    timestamp = current_time()
    write_manifest(backup_dir, timestamp, manifest)
    copy_files(source_dir, backup_dir, manifest)
    return manifest

"""
When writing the manifest, we check that the backup directory exists, create
it if it does not, and then save the manifest as CSV
"""

def write_manifest(backup_dir, timestamp, manifest):
    backup_dir = Path(backup_dir)
    if not backup_dir.exists():
        backup_dir.mkdir()

    manifest_file = Path(backup_dir, f"{timestamp}.csv")
    with open(manifest_file, "w") as raw:
        writer = csv.writer(raw)
        writer.writerow(["filename", "hash"])
        writer.writerows(manifest)

"""
We then copy those files that haven’t already been saved:
"""

def copy_files(source_dir, backup_dir, manifest):
    for (filename, hash_code) in manifest:
        source_path = Path(source_dir, filename)
        backup_path = Path(backup_dir, f"{hash_code}.bck")
        if not backup_path.exists():
            shutil.copy(source_path, backup_path)

#+end_src

- We have introduced several more race conditions here:

  for example, if two people are creating backups at the same time, they could both discover that the backup directory doesn’t exist and then both try to create it.

  Whoever does so first will succeed, but whoever comes second will fail.

- Our backup function relies on a helper function called ~current_time~ that does nothing but call ~time.time~ from Python’s standard library:

  *Q.* Why ?
  *A.* We could call ~time.time~ directly, but wrapping it up like this makes it easier to replace with a mock for testing.

#+begin_src python :tangle ./src/ch10/backup.py

def current_time():
    return f"{time.time()}".split(".")[0]
#+end_src

Let’s do one test with real files:

#+begin_src python :tangle ./src/ch10/backup.py

import sys
from pprint import pprint

if __name__ == '__main__':
    args = sys.argv[1:]
    source_dir = args[0]
    backup_dir = args[1]

    manifest = backup(source_dir, backup_dir)
    pprint(manifest)
#+end_src

#+begin_src sh
BACKUPS=/tmp/backups
[ -d "$BACKUPS" ] && trash "$BACKUPS"
uv run ./src/ch10/backup.py ./src/ch10/sample_dir/ "$BACKUPS"
echo
tree --charset ascii "$BACKUPS"
#+end_src

#+RESULTS:
#+begin_example
[('a.txt', '17e682f060b5f8e4'),
 ('b.txt', '3cf9a1a81f6bdeaf'),
 ('sub_dir/c.txt', '5695d82a086b6779')]

/tmp/backups
|-- 1756539204.csv
|-- 17e682f060b5f8e4.bck
|-- 3cf9a1a81f6bdeaf.bck
`-- 5695d82a086b6779.bck

1 directory, 4 files
#+end_example

The rest of our tests use a fake filesystem and a mock replacement for the ~current_time~ function (so that we know what the manifest file will be called). The setup is:

#+begin_src python :tangle ./src/ch10/test_backup.py
import pyfakefs
import pytest
from unittest.mock import patch
from backup import backup
from pathlib import Path

FILES = {"a.txt": "aaa", "b.txt": "bbb", "sub_dir/c.txt": "ccc"}

@pytest.fixture
def our_fs(fs):
    for name, contents in FILES.items():
        fs.create_file(name, contents=contents)

"""
Example of a single test (num-num power)
"""

def test_nested_example(our_fs):
    timestamp = 1234
    with patch("backup.current_time", return_value=timestamp):
        manifest = backup(".", "/backup")
    assert Path("/backup", f"{timestamp}.csv").exists()
    for filename, hash_code in manifest:
        assert Path("/backup", f"{hash_code}.bck").exists()

#+end_src

#+begin_src sh
uvx --with pyfakefs pytest ./src/ch10/
#+end_src

#+RESULTS:
#+begin_example
=============================== test session starts ================================
platform linux -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0
rootdir: /home/nabeel/Documents/public/books/Software Design by Example
plugins: pyfakefs-5.9.3
collected 6 items

src/ch10/test_backup.py .                                                    [ 16%]
src/ch10/test_hash_all.py ..                                                 [ 50%]
src/ch10/test_mock_fs.py .                                                   [ 66%]
src/ch10/test_mock_tree.py ..                                                [100%]

================================ 6 passed in 0.04s =================================
#+end_example

*** Refactoring

Now that we have a better idea of what we’re doing, we can refactor to create a base class that prescribes the general steps in creating a backup:

#+begin_src python
class Archive:
    def __init__(self, source_dir):
        self._source_dir = source_dir

    def backup(self):
        manifest = hash_all(self._source_dir)
        self._write_manifest(manifest)
        self._copy_files(manifest)
        return manifest
#+end_src

We can then derive a child class to archive things locally and fill in its methods by re-using code from the functions we have just written. Once we’ve done this, we can create the specific archiver we want with a single line:

#+begin_src python
archiver = ArchiveLocal(source_dir, backup_dir)
#+end_src

Doing this makes life easier when we want to write archivers that /behave the same way/ BUT work differently.

- For example, we could create an archiver that /compresses/ the files it archives by deriving a new class from ~ArchiveLocal~ and writing a new ~_copy_files~ method.

  More importantly, other code can use an archiver /without knowing what it’s doing/.

- For example, the function ~analyze_and_save~ reads some data, analyzes it, saves the results, and then creates an archive of those results.

  It doesn’t know whether the archive is compressing files or whether they’re being saved locally or remotely.

#+begin_src python
def analyze_and_save(options, archiver):
    data = read_data(options)
    results = analyze_data(data)
    save_everything(results)
    archiver.backup()
#+end_src

- Strength of OOP :: This example highlights one of the strengths of object-oriented programming: it allows old code to use new code without any changes.

* Chapter 11: An HTML Validator
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/check/
:header-args:python: :session ch11 :results output :async yes :eval no
:header-args:sh: :session ch11-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       d7cf25df-a9fd-4991-a251-00387dd5bfa3
:END:

- HTML consists of text and of elements represented by tags with attributes.
- HTML is represented in memory as a Document Object Model (DOM) tree.

- Trees are usually processed using recursion.

- The Visitor design pattern is often used to perform an action for each member of a data structure.

- We can summarize and check the structure of an HTML page by visiting each node and recording what we find there.

Suppose we want to generate web pages to show the results of data analyses.

We want to check that these pages all have the same structure so that people can find things in them, and that they meet accessibility standards so that everyone can find things in them.

This chapter builds a small tool to do this checking, which introduces ideas we will use in building a page generator ([[*Chapter 12: A Template Expander][Chapter 12: A Template Expander]]) and another to check the structure and style of our code ([[*Chapter 13: A Code Linter][Chapter 13: A Code Linter]]).

HTML is probably the most widely used data format in the world today; Figure 11.3 summarizes how it is represented and processed.

#+caption: Concept map for Checking HTML using Visitor patter
[[file:images/Chapter_11:_An_HTML_Validator/2025-09-01_16-31-27_screenshot.png]]

** Theory
*** HTML and the DOM
:PROPERTIES:
:ID:       4a1c9567-25ad-40c2-a9fd-27f7187a3e8e
:END:
In HTML, a document’s elements form a tree of nodes and text like the one shown in Figure 11.1.

#+caption: Representing HTML elements as a DOM tree
[[file:images/Chapter_11:_An_HTML_Validator/2025-09-01_16-34-24_screenshot.png]]

This figure also shows that opening and self-closing tags can have attributes, which are written as key="value". For example, if we want to put an image in an HTML page, we specify the image file’s name using the src attribute of the img tag:

#+begin_src html
<img src="banner.png" />
#+end_src

The objects that represent the nodes and text in an HTML tree are called the Document Object Model or *DOM*. Hundreds of tools have been written to convert HTML text to DOM; our favorite is a Python module called 'Beautiful Soup', which can handle messy real-world documents as well as those that conform to every rule of the standard.

Beautiful Soup’s DOM has two main classes: =NavigableString= for text and =Tag= for elements. To parse a document, we import what we need and call BeautifulSoup with the text to be parsed and a string specifying exactly what kind of parsing we want to do. (In practice, this is almost always "html.parser".)

#+begin_src python :tangle ./src/ch11/parse.py :noweb yes
from bs4 import BeautifulSoup, NavigableString, Tag

text = """<html>
<body>
<h1>Title</h1>
<p>paragraph</p>
</body>
</html>"""

<<display-12>>

doc = BeautifulSoup(text, "html.parser")
display(doc)
#+end_src

Tag nodes have two properties name and children to tell us what element the tag represents and to give us access to the node’s children, i.e., the nodes below it in the tree. We can therefore write a short recursive function to show us everything in the DOM:

#+name: display-12
#+begin_src python
def display(node):
    if isinstance(node, NavigableString):
        print(f"string: {repr(node.string)}")
        return
    else:
        print(f"node: {node.name}")
        for child in node:
            display(child)
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch11/parse.py
#+end_src

#+RESULTS:
#+begin_example
node: [document]
node: html
string: '\n'
node: body
string: '\n'
node: h1
string: 'Title'
string: '\n'
node: p
string: 'paragraph'
string: '\n'
string: '\n'
#+end_example

- NOTE :: Notice in the output that the line breaks in the HTML (in ~text~ variable) have been turned into text nodes containing only a newline character.

  - It’s easy to forget about these when writing code that processes pages. (True)

The last bit of the DOM that we need is its representation of /attributes/.
Each =Tag= node has a dictionary called ~attrs~ that stores the node’s attributes.
The values in this dictionary are either strings or lists of strings depending on whether the attribute has a single value or multiple values:

#+begin_src python :tangle ./src/ch11/attrs.py
from bs4 import BeautifulSoup, NavigableString, Tag

text = """<html lang="en">
<body class="outline narrow">
<p align="left" align="right">paragraph</p>
</body>
</html>"""

def display(node):
    if isinstance(node, Tag):
        print(f"node: {node.name} {node.attrs}")
        for child in node:
            display(child)

doc = BeautifulSoup(text, "html.parser")
display(doc)
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch11/attrs.py
#+end_src

#+RESULTS:
: node: [document] {}
: node: html {'lang': 'en'}
: node: body {'class': ['outline', 'narrow']}
: node: p {'align': 'right'}

*** The Visitor Pattern
:PROPERTIES:
:ID:       3f4c15db-e479-4a6e-b022-ea0272e85ee6
:END:

- Visitor patter ::
  A design pattern in which the operation to be done is taken to each element of a data structure in turn.

  It is usually implemented by having a generator “visitor” that knows how to reach the structure’s elements, which is GIVEN a function or method to call for each in turn, and that carries out the specific operation.

  - NOTE :: the more complicated the data structure is, the more helpful the Visitor pattern becomes.

A visitor is a class that knows how to get to each element of a data structure and call a user-defined method when it gets there. Our visitor will have three methods:

- one that it calls when it first encounters a node,
- one that it calls when it is finished with that node, and
- one that it calls for text

#+begin_src python :tangle ./src/ch11/visitor.py
class Visitor:
    def visit(self, node):
        if isinstance(node, NavigableString):
            self._text(node)

        elif isinstance(node, Tag):
            self._tag_enter(node)
            for child in node:
                self.visit(child)
            self._tag_exit(node)

    def _tag_enter(self, node): pass

    def _tag_exit(self, node): pass

    def _text(self, node): pass
#+end_src

#+caption: Visitor checking each node in depth-first order (like DFS)
[[file:images/Chapter_11:_An_HTML_Validator/2025-09-01_16-49-25_screenshot.png]]

- NOTE :: We provide /do-nothing/ implementations of the three action methods rather than having them raise a =NotImplementedError= because a particular use of our Visitor class may not need some of these methods.

  For example, our catalog builder didn’t need to do anything when leaving a node or for text nodes, and we shouldn’t require people to implement things they don’t need.

Here’s what our catalog builder looks like when re-implemented on top of our Visitor class:

#+begin_src python :tangle ./src/ch11/catalog.py
import sys
from visitor import Visitor

class Catalog(Visitor):
    def __init__(self):
        super().__init__()
        self.catalog = {}

    def _tag_enter(self, node):
        if node.name not in self.catalog:
            self.catalog[node.name] = set()
        for child in node:
            if isinstance(child, Tag):
                self.catalog[node.name].add(child.name)

with open(sys.argv[1], "r") as reader:
    text = reader.read()
doc = BeautifulSoup(text, "html.parser")

cataloger = Catalog()
cataloger.visit(doc.html)
result = cataloger.catalog

for tag, contents in sorted(result.items()):
    print(f"{tag}: {', '.join(sorted(contents))}")

#+end_src

*** Checking Style

To wrap up our style checker, let’s create a manifest that specifies which types of nodes can be children of which others:

#+begin_src yaml :tangle ./src/ch11/manifest.yml
body:
- section
head:
- title
html:
- body
- head
section:
- h1
- p
- ul
ul:
- li
#+end_src

We’ve chosen to use YAML for the manifest because it’s a relatively simple way to write nested rules. JSON would have worked just as well, but as we said in [[*Chapter 5: Parsing Text][Chapter 5: Parsing Text]], we shouldn’t invent a syntax of our own: there are already too many in the world.

Our ~Check~ class needs a constructor to set everything up and a ~_tag_enter~ method to handle nodes:

#+begin_src python :tangle ./src/ch11/check.py
class Check(Visitor):
    def __init__(self, manifest):
        self.manifest = manifest
        self.problems = {}

    def _tag_enter(self, node):
        actual = {child.name for child in node
                  if isinstance(child, Tag)}
        errors = actual - self.manifest.get(node.name, set()) # V.Nice !!!
        if errors:
            errors |= self.problems.get(node.name, set())
            self.problems[node.name] = errors

#+end_src

- NOTE :: See how cleanly we implement the manner to determine which node's are breaking the rules in our manifest.
  We do a set difference, i.e ~errors = actual - allowed~.

To run this, we load a manifest and an HTML document, create a checker, ask the checker to visit each node, then print out every problematic parent-child combination it found:

#+begin_src python :tangle ./src/ch11/check.py
def read_manifest(filename):
    with open(filename, "r") as reader:
        result = yaml.load(reader, Loader=yaml.FullLoader)
        for key in result:
            result[key] = set(result[key]) # convert values from list -> set
        return result

manifest = read_manifest(sys.argv[1])
with open(sys.argv[2], "r") as reader:
    text = reader.read()
doc = BeautifulSoup(text, "html.parser")

checker = Check(manifest)
checker.visit(doc.html)
for key, value in checker.problems.items():
    print(f"{key}: {', '.join(sorted(value))}")

#+end_src

* Chapter 12: A Template Expander
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/template/
:header-args:python: :session ch12 :results output :async yes :eval no
:header-args:sh: :session ch12-sh :results output :async yes
:GPTEL_TOPIC: chapter-12:-a-template-expander
:END:

** Summary
:PROPERTIES:
:ID:       96bbe796-ffbf-40f9-903d-7bcd0cd8b74b
:END:

+ Static site generators create HTML pages from templates, directives, and data.

+ A static site generator has _THE SAME CORE FEATURES_ as a programming language.
+ Special-purpose mini-languages quickly become as complex as other languages.

+ Static methods are :: a convenient way to group functions together.

#+caption: HTML templating concept map
[[file:images/Chapter_12:_A_Template_Expander/2025-09-01_13-36-52_screenshot.png]]

- Every program needs documentation, and the best place to put documentation is on the web.
  Writing and updating HTML pages by hand is time-consuming and error-prone, particularly when many parts are the same.

  Most modern websites therefore use some kind of static site generator (SSG) to create pages from templates.

Most of these systems use one of three designs (Figure 12.1):

#+caption: Three different ways to implement page templating
[[file:images/Chapter_12:_A_Template_Expander/2025-09-01_13-39-41_screenshot.png]]

1. Mix commands in an existing language such as JavaScript with the HTML or Markdown using some kind of marker to indicate which parts are commands and which parts are to be taken as-is. This approach is taken by EJS.

2. Create a mini-language with its own commands like Jekyll.

   Mini-languages are appealing because they are smaller and safer than general-purpose languages, _BUT_ eventually they acquire most of the features of a general-purpose language.

   Again, some kind of marker must be used to show which parts of the page are code and which are ordinary text.

3. Put directives in specially-named attributes in the HTML. This approach is the least popular, but it eliminates the need for a special parser.


- This chapter builds a simple page templating system using the third strategy.

  We will process each page independently by parsing the HTML and walking the DOM to find nodes with special attributes.

  Our program will execute the instructions in those nodes to implement loops and if/else statements; other nodes will be copied as-is to create text.

** Theory
*** Syntax
:PROPERTIES:
:ID:       d5656182-1ad1-47fc-be08-363d81c82c8c
:END:

Let’s start by deciding what “done” looks like. Suppose we want to turn an array of strings into an HTML list. Our template will look like this:

#+begin_src html
<html>
  <body>
    <ul z-loop="item:names">
      <li><span z-var="item"/></li>
    </ul>
  </body>
</html>
#+end_src

The attribute =z-loop= tells the tool to repeat the contents of that node;
the loop variable and the collection being looped over are separated by a colon.
The =span= with the attribute =z-var= tells the tool to fill in the node with the value of the variable.

When our tool processes this page, the output will be standard HTML without any traces of how it was created:

#+begin_src html
<html>
<body>
<ul>
<li><span>Johnson</span></li>

<li><span>Vaughan</span></li>

<li><span>Jackson</span></li>
</ul>
</body>
</html>
#+end_src

#+caption: Human Readable vs Machine Readable
#+begin_quote
Putting the loop variable and target in a single attribute makes loops easy to type but hides information from standard HTML tools, which can’t know that this attribute contains multiple values separated by a colon. We should use two attributes like this:

~<ul z-loop="names" z-loop-var="item">~

but we decided to save ourselves a little typing.

We should also call our attributes data-something instead of z-something to conform with the HTML5 specification, but again, decided to save ourselves a bit of typing.
#+end_quote

- The next step is to define the Application Programming Interface (API) for filling in templates.

  Our tool needs:
  1. the template itself,
  2. somewhere to write its output, and
  3. the set of variables to use in the expansion.

  Those variables might come from:
  - a configuration file
  - from a header in the file itself, or
  - from somewhere else entirely,

  so we will assume the calling program has gotten them somehow and have it pass them into the expansion function as a dictionary.

#+begin_src python
data = {"names": ["Johnson", "Vaughan", "Jackson"]}

dom = read_html("template.html")
expander = Expander(dom, data)
expander.walk()
print(expander.result)
#+end_src

#+caption: Combining text and data in templating
[[file:images/Chapter_12:_A_Template_Expander/2025-09-01_13-46-35_screenshot.png]]

*** Managing Variables (How ?)

As soon as we have variables, _we need a way to track their values_.

We also need to maintain multiple sets of variables so that (for example) variables used inside a loop don’t conflict with ones used outside of it.

As in [[*Chapter 7: An Interpreter][Chapter 7: An Interpreter]], we will use a /stack of environments/, each of which is a dictionary.

#+begin_src python :tangle ./src/ch12/env.py
class Env:
    def __init__(self, initial):
        self.stack = [initial.copy()]

    def push(self, frame):
        self.stack.append(frame)

    def pop(self):
        self.stack.pop()

    def find(self, name):
        for frame in reversed(self.stack):
            if name in frame:
                return frame[name]
        return None
#+end_src

Our stack-handling class ~Env~ has methods to push and pop new stack frames and find a variable given its name. If the variable can’t be found, ~Env.find~ returns /None/ instead of raising an exception.

*** Visiting Nodes

As [[*Chapter 11: An HTML Validator][Chapter 11: An HTML Validator]] explained, HTML pages are usually stored in memory as trees and processed using the *Visitor pattern*.

We therefore create a ~Visitor~ class whose constructor takes the root node of the DOM tree as an argument and saves it. Calling ~Visitor.walk~ without a value starts recursion from that saved root; when ~.walk~ is given a value (as it is during recursive calls), it uses that instead.

#+begin_src python :tangle ./src/ch12/visitor.py


class Visitor:
    def __init__(self, root):
        self.root = root
        # Here a node will be a BeautifulSoup node

    def walk(self, node=None):
        if node is None:
            node = self.root

        opened = self.open(node)
        # The 'open' method apart from its return value
        # also has 'side-effects', i.e it opens the node
        if opened:
            for child in node.children:
                self.walk(child)

        self.close(node)

    def open(self, node):
        raise NotImplementedError("open")

    def close(self, node):
        raise NotImplementedError("close")
#+end_src

~Visitor~ defines two *abstract methods* ~open~ and ~close~ that are called when we first arrive at a node and when we are finished with it.

These methods are called “abstract” because we can’t actually use them: any attempt to do so will raise an exception, which means child classes must override them. (In object-oriented terminology, this means that ~Visitor~ is an *abstract class*.)

- NOTE :: This approach is different from that of the visitor in [[*Chapter 11: An HTML Validator][Chapter 11: An HTML Validator]], where we defined /do-nothing/ methods so that derived classes could override only the ones they needed.


The ~Expander~ class is specialization of ~Visitor~ that uses an ~Env~ to keep track of variables.

It imports handlers for each type of special node -- we will explore those in a moment -- and saves them along with a newly-created environment and a list of strings making up the output:

#+begin_src python :tangle ./src/ch12/expander.py :noweb yes
from env import Env
from visitor import Visitor
from bs4 import NavigableString

<<import handlers>>

class Expander(Visitor):
    def __init__(self, root, variables):
        super().__init__(root)
        self.env = Env(variables) # variables is a dict of variable: value
        self.handlers = HANDLERS # dict of special_attribute: special_object_object
        self.result = []

    <<Expander open close>>
    <<Expander handler helper methods>>
    <<Expander helper methods>>
#+end_src

- When recursion encounters a new node, it calls open to do one of three things:

  1. If the node is plain text, copy it to the output.
     - NOTE :: Here the output _ISN'T_ stdout (Flexible)

  2. If there is a handler for the node, call the handler’s ~open~ or ~close~ method.

  3. Otherwise, open a regular tag.

#+name: Expander open close
#+begin_src python
def open(self, node):
    if isinstance(node, NavigableString):
        self.output(node.string)
        return False
    elif self.hasHandler(node):
        # The handler is supposed to handle itself
        # as-well-as open the node it is in.
        return self.getHandler(node).open(self, node)
    else:
        self.showTag(node, closing=False)
        # showTag handles a normal html node's opening/closing
        return True

def close(self, node):
    if isinstance(node, NavigableString):
        pass
    elif self.hasHandler(node):
        # The handler is supposed to handle itself
        # as-well-as close the node it is in.
        return self.getHandler(node).close(self, node)
    else:
        self.showTag(node, closing=True)
        # showTag handles a normal html node's opening/closing
        return True

#+end_src

Both methods find handlers by comparing the DOM node’s attributes to the keys in the dictionary of handlers built during construction:

#+name: Expander handler helper methods
#+begin_src python
def hasHandler(self, node):
    return any(
        name in self.handlers
        for name in node.attrs
    )

def getHandler(self, node):
    possible = [
        name for name in node.attrs
        if name in self.handlers
    ]
    assert len(possible) == 1, "Should be exactly one handler"
    return self.handlers[possible[0]]

#+end_src

Finally, we need a few helper methods to show tags and generate output:

#+name: Expander helper methods
#+begin_src python
def showTag(self, node, closing):
    if closing:
        self.output(f"</{node.name}>")
        return
    self.output(f"<{node.name}")

    # If opening:
    for name in node.attrs:
        # showTag is also used by the handler functions themselves
        # therefore we must remove any attributes that start with 'z-'
        if not name.startswith("z-"):
            self.output(f' {name}="{node.attrs[name]}"')
    self.output(">")

def output(self, text):
    # Doesn't output to stdout !!
    self.result.append("UNDEF" if text is None else text)

def getResult(self):
    return "".join(self.result)

#+end_src

- NOTE ::  that ~Expander~ adds strings to an array and joins them all right at the end rather than concatenating strings repeatedly.

  Doing this is more efficient; it also helps with debugging, since each string in the array corresponds to a single method call.

*** Implementing Handlers

- AIM :: Our last task is to implement the handlers for filling in variables’ values, looping, and so on.

  We could define an /abstract class/ with ~open~ and ~close~ methods, derive one class for each of the template expander’s capabilities, and then construct one instance of each class for ~Expander~ to use, _but there’s a simpler way_.

  - When Python executes the statement ~import something~ it
    - executes the file /something.py/,
    - saves the result in a specialized dictionary-like object, and
    - assigns that object to the variable /something/.

    That object can also be saved in data structures like lists and dictionaries or passed as an argument to a function just like numbers, functions, and classes -- _REMEMBER, PROGRAMS ARE JUST DATA_.

Let’s expand a DOM node with a =z-num= attribute to insert a number into the output:
#+begin_src python :tangle ./src/ch12/z_num.py
def open(expander, node):
    expander.showTag(node, closing=False)
    expander.output(node.attrs["z-num"])

def close(expander, node):
    expander.showTag(node, closing=True)
#+end_src

- NOTE :: How we bring together ~Expander~ and our special handlers

  - the handler :: takes in ~Expander~ as its first argument, and the node as the data it needs to act on.
    Throughout the handler /handles/ which method of the ~Expander~ to call and how to call it.

    In this manner the handler can be defined apart from the ~Expander~ class.

  - the ~Expander~ :: passes itself into the hands of the handler as its first argument.

When we enter a node like ~<span z-num="123"/>~ this handler asks the expander to show an opening tag followed by the value of the =z-num= attribute.

When we exit the node, the handler asks the expander to close the tag.

The handler DOESN’T KNOW whether things are printed immediately, added to an output list, or something else; it just knows that whoever called it implements the low-level operations it needs.

Here’s how we connect this handler (and others we’re going to write in a second) to the expander:

#+caption: we are using modules to prevent name collision just as we would use classes or functions.
#+name: import handlers
#+begin_src python
import z_if
import z_loop
import z_num
import z_var

HANDLERS = {
    "z-if": z_if,
    "z-loop": z_loop,
    "z-num": z_num,
    "z-var": z_var
}

#+end_src

#+begin_src python :tangle ./src/ch12/z_var.py
def open(expander, node):
    expander.showTag(node, closing=False)
    expander.output(expander.env.find(node.attrs["z-var"]))

def close(expander, node):
    expander.showTag(node, closing=True)

#+end_src

#+caption: Generating Element IDs
#+begin_quote
It’s often handy to have a unique identifier for every element in a page, so some templating engines automatically generate id attributes for elements that don’t specify IDs explicitly.

- If you do this, please _DO NOT_ generate random numbers, because then Git and other version control systems will think a regenerated page has changed when it actually hasn’t.

- Generating sequential IDs is equally problematic:
  if you add an item to a list at the top of the page, for example, that might change the IDs for all of the items in subsequent (unrelated) lists.

*Q.* What to do then ?
#+end_quote

*** Some tests

To check if they work:

#+caption: Our variables to be used in different tests
#+begin_src python :tangle ./src/ch12/vars.json
{
  "firstVar": "firstValue",
  "secondVar": "secondValue",
  "varName": "varValue",
  "yes": true,
  "no": false,
  "names": ["Johnson", "Vaughan", "Jackson"]
}
#+end_src

Our main function builds a program that loads variable definitions from a JSON file, reads an HTML template using the Beautiful Soup module, and does the expansion:

#+begin_src python :tangle ./src/ch12/template.py
import json
import sys
from bs4 import BeautifulSoup
from expander import Expander

def main():
    with open(sys.argv[1], "r") as reader:
        variables = json.load(reader)

    with open(sys.argv[2], "r") as reader:
        doc = BeautifulSoup(reader.read(), "html.parser")
        template = doc.find("html")

    expander = Expander(template, variables)
    expander.walk()
    print(expander.getResult())

if __name__ == "__main__":
    main()

#+end_src


#+caption: checks whether static text is copied over as-is
#+begin_src html :tangle ./src/ch12/static_text.templ
<html>
  <body>
    <h1>Static Text</h1>
    <p>test</p>
  </body>
</html>
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/static_text.templ
#+end_src

#+RESULTS:
: <html>
: <body>
: <h1>Static Text</h1>
: <p>test</p>
: </body>
: </html>

#+caption: does the expander handle constants?
#+begin_src html :tangle ./src/ch12/single_constant.templ
<html>
  <body>
    <p><span z-num="123"/></p>
  </body>
</html>
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/single_constant.templ
#+end_src

#+RESULTS:
: <html>
: <body>
: <p><span>123</span></p>
: </body>
: </html>

#+caption: What about a single variable?
#+begin_src html :tangle ./src/ch12/single_variable.templ
<html>
  <body>
    <p><span z-var="varName"/></p>
  </body>
</html>
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/single_variable.templ
#+end_src

#+RESULTS:
: <html>
: <body>
: <p><span>varValue</span></p>
: </body>
: </html>

#+caption: What about a page containing multiple variables?
#+begin_src html :tangle ./src/ch12/multiple_variables.templ
<html>
  <body>
    <p><span z-var="firstVar" /></p>
    <p><span z-var="secondVar" /></p>
  </body>
</html>
#+end_src

There’s no reason it should fail if the single -- variable case works, but we should still check -- again, SOFTWARE ISN’T DONE UNTIL IT HAS BEEN TESTED.

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/multiple_variables.templ
#+end_src

#+RESULTS:
: <html>
: <body>
: <p><span>firstValue</span></p>
: <p><span>secondValue</span></p>
: </body>
: </html>

*** Control Flow

Our tool supports conditional expressions and loops.

Since we’re not implementing Boolean expressions like and and or, all we have to do for a condition is look up a variable and then expand the node if Python thinks the variable’s value is truthy:

#+begin_src python :tangle ./src/ch12/z_if.py
def open(expander, node):
    check = expander.env.find(node.attrs["z-if"])
    if check:
        expander.showTag(node, closing=False)
    return check

def close(expander, node):
    check = expander.env.find(node.attrs["z-if"])
    if check:
        expander.showTag(node, closing=True)

#+end_src

#+begin_src html :tangle ./src/ch12/conditional.templ
<html>
  <body>
    <p z-if="yes">Should be shown.</p>
    <p z-if="no">Should <em>not</em> be shown.</p>
  </body>
</html>
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/conditional.templ
#+end_src

#+RESULTS:
: <html>
: <body>
: <p>Should be shown.</p>
:
: </body>
: </html>

#+caption: Spot the bug
#+begin_quote
This implementation of if contains a subtle bug.

~open~ and ~close~ both check the value of the control variable.
If something inside the body of the if changes that value, the result could be an opening tag without a matching closing tag or vice versa.

We haven’t implemented an assignment operator, so right now there’s no way for that to happen, but it’s a plausible thing for us to add later, and /tracking down a bug in old code that is revealed by new code is always a headache/.
#+end_quote

*Q.* How to solve this bug ?
*A.* (AI answer)

To solve this, the boolean result of the =z-if= condition should be computed /once/ during the =open= call and then stored. This stored value should then be retrieved and used by the corresponding =close= call.

A practical way to implement this, given the current =Visitor= pattern, is for the =Expander= class to maintain a stack of these =z-if= decisions.
1.  In =Expander.open=, if a =z-if= handler is found, call =z_if.open= to get the condition's result (=check=). Store this =check= value on a dedicated stack within =Expander= (e.g., =self.if_decision_stack=).
2.  In =Expander.close=, if a =z-if= handler is found, pop the original =check= value from =self.if_decision_stack= and pass it to =z_if.close=.
3.  Modify =z_if.close= to accept and use this passed =check= value instead of re-evaluating the condition.


Finally we have loops. For these, we need to get the array we’re looping over from the environment and do the following for each item it contains:

1. Create a new stack frame holding the current value of the loop variable.
2. Expand all of the node’s children with that stack frame in place.
3. Pop the stack frame to get rid of the temporary variable.

#+begin_src python :tangle ./src/ch12/z_loop.py
def open(expander, node):
    index_name, target_name = node.attrs["z-loop"].split(":")
    expander.showTag(node, closing=False)
    target = expander.env.find(target_name)
    for value in target:
        expander.env.push({index_name: value})
        for child in node.children:
            expander.walk(child) # our handler needs to call this for the if body
        expander.env.pop()
    return False

def close(expander, node):
    expander.showTag(node, closing=True)

#+end_src

- NOTE :: the z_loop ~open~ function always returns False.
  If it didn't then, ~Visitor~ would have recursed.
  In this way it hijacks what the ~Visitor~ would have done with its own implementation.

#+caption: Not done until we test it
#+begin_src html :tangle ./src/ch12/loop.templ
<html>
  <body>
    <ul z-loop="item:names">
      <li><span z-var="item"/></li>
    </ul>
  </body>
</html>
#+end_src

#+begin_src sh
uv run --with beautifulsoup4 ./src/ch12/template.py \
   ./src/ch12/vars.json \
   ./src/ch12/loop.templ
#+end_src

#+RESULTS:
#+begin_example
<html>
<body>
<ul>
<li><span>Johnson</span></li>

<li><span>Vaughan</span></li>

<li><span>Jackson</span></li>
</ul>
</body>
</html>
#+end_example

*** Final
- WOW :: We have just implemented another simple programming language like the one in [[*Chapter 7: An Interpreter][Chapter 7: An Interpreter]].

It’s unlikely that anyone would want to use it as-is, but adding a new feature is now as simple as writing a matching pair of open and close functions.

* Chapter 13: A Code Linter
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/lint/
:header-args:python: :session ch13 :results output :async yes :eval no
:header-args:sh: :session ch13-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       8e394afc-5835-4a6d-9de7-6fd6fd5e7f8f
:END:

 - A linter checks that a program conforms to a set of style and usage rules.
 - Linters /typically use/ the Visitor design pattern to find nodes of interest in an abstract syntax tree.

 - Programs CAN MODIFY a program's AST and then unparse it to create modified versions of the original program.
 - Dynamic code modification is very powerful, BUT the technique can produce insecure and unmaintainable code.

Checking tools are often called *linters* because an early tool like this that found fluff in C programs was called /lint/.
Many projects insist that code pass linting checks before being committed to version control.

To show how linters work, this chapter builds a trio of tools that:
 * find duplicate keys in dictionaries,
 * look for unused variables, and
 * create a table showing which classes in a hierarchy define which methods.

#+caption: Concepts for code manipulation
[[file:images/Chapter_13:_A_Code_Linter/2025-09-02_17-07-17_screenshot.png]]

** Theory
*** Machinery
:PROPERTIES:
:ID:       8ce28f1f-b373-4eca-a775-530a19f31e61
:END:

[[*Chapter 11: An HTML Validator][Chapter 11: An HTML Validator]] represented HTML as a DOM tree.
We can also represent the structure of a program as an abstract syntax tree (AST) whose nodes represent functions, statements, variables, array indexing operations, and so on.

Python’s [[https://docs.python.org/3/library/ast.html][ast]] module will parse Python source code and produce an AST for us.
For example, [[Figure 13.1]] shows key parts of the AST for the short program shown below:

#+begin_src python :tangle ./src/ch13/simple.py
def double(x):
    return 2 * x

result = double(3)
print(result)
#+end_src

#+name: Figure 13.1
#+caption: The abstract syntax tree for a simple Python program.
[[file:images/Chapter_13:_A_Code_Linter/2025-09-02_17-09-53_screenshot.png]]

We said “key parts of the AST” because the complete structure contains many details that we haven’t bothered to draw. To see them, let’s use ~ast.parse~ to turn our example code into an AST and ~ast.dump~ to display it:

#+begin_src python :eval yes :tangle ./src/ch13/dump_ast.py
import ast
import sys

with open(sys.argv[1], "r") as reader:
    source = reader.read()

tree = ast.parse(source)
print(ast.dump(tree, indent=4))
#+end_src

#+begin_src sh
uv run ./src/ch13/dump_ast.py ./src/ch13/simple.py
#+end_src

#+RESULTS:
#+begin_example
Module(
    body=[
        FunctionDef(
            name='double',
            args=arguments(
                posonlyargs=[],
                args=[
                    arg(arg='x')],
                kwonlyargs=[],
                kw_defaults=[],
                defaults=[]),
            body=[
                Return(
                    value=BinOp(
                        left=Constant(value=2),
                        op=Mult(),
                        right=Name(id='x', ctx=Load())))],
            decorator_list=[],
            type_params=[]),
        Assign(
            targets=[
                Name(id='result', ctx=Store())],
            value=Call(
                func=Name(id='double', ctx=Load()),
                args=[
                    Constant(value=3)],
                keywords=[])),
        Expr(
            value=Call(
                func=Name(id='print', ctx=Load()),
                args=[
                    Name(id='result', ctx=Load())],
                keywords=[]))],
    type_ignores=[])
#+end_example

The node representing the definition of the function double is a =FunctionDef= node with a /name/ and an /arguments/ sub-node that stores information about the function’s arguments.

- If we want a list of all the functions defined in this module, we can walk through this tree to find all the ~FunctionDef~ nodes and record their name properties.

  - Since each node’s structure is a little different, we would have to write one function for each type of node that knew which fields of that node were worth exploring.
    (True)

Luckily for us the ~ast~ module has tools to do this for us.
The class ~ast.NodeVisitor~ uses the now-familiar Visitor design pattern to recurse through a structure like the one in [[Figure 13.1]].

Each time the visitor reaches a node of type /Thing/, it looks for a method called /visit_Thing/;
for example, when it reaches a =FunctionDef= node it looks for ~visit_FunctionDef~. If that method has been defined, ~NodeVisitor~ calls it with the node as an argument.

The class ~CollectNames~ uses this machinery to create a list of the function and variable names defined in a program:

#+begin_src python :tangle ./src/ch13/walk_ast.py
import ast
import sys

class CollectNames(ast.NodeVisitor):
    def __init__(self):
        super().__init__()
        self.names = {} # this is a dict (NOT a set !)

    def visit_Assign(self, node):
        # see 'targets' in 'Assign' of our ast dump of the previous example
        for var in node.targets:
            self.add(var, var.id)
        self.generic_visit(node) # generic_visit is a NodeVisitor method

    def visit_FunctionDef(self, node):
        self.add(node, node.name)
        self.generic_visit(node)

    def add(self, node, name):
        loc = (node.lineno, node.col_offset)
        self.names[name] = self.names.get(name, set())
        self.names[name].add(loc)

    def position(self, node):
        return ({node.lineno}, {node.col_offset})

#+end_src

A few things worth noting about this class are:

1. The constructor of ~CollectNames~ invokes the constructor of ~NodeVisitor~ using ~super().__init__()~ before doing anything else.

2. The methods ~visit_Assign~ and ~visit_FunctionDef~ must call ~self.generic_visit(node)~ explicitly to recurse down through their children.

   - By requiring this to be explicit, ~NodeVisitor~ gives programmers control on whether and when recursion takes place.

3. The method ~position~ relies on the fact that every node in the AST keeps track of where in the source code it came from.

To use this class, we read the source of the program that we want to analyze, parse it, and then call the visit method of our class to trigger recursion:

#+begin_src python :tangle ./src/ch13/walk_ast.py
with open(sys.argv[1], 'r') as reader:
    source = reader.read()
tree = ast.parse(source)
collector = CollectNames()
collector.visit(tree)
print(collector.names)
#+end_src

#+begin_src sh
uv run ./src/ch13/walk_ast.py ./src/ch13/simple.py
#+end_src

#+RESULTS:
: {'double': {(1, 0)}, 'result': {(4, 0)}}

With a little more work we could record class names as well, and then check that (for example) class names use CamelCase, while function and variable names use pothole_case.

*** Finding Duplicate Keys

Many programs store their configuration in dictionaries. As those dictionaries grow larger, it’s easy for programmers to redefine values by accident.

For example, the dictionary in this short piece of code has two entries for the key "third":
#+name: has_duplicate_keys
#+begin_src python :eval yes :tangle ./src/ch13/has_duplicate_keys.py
has_duplicates = {
    "third": 3,
    "fourth": 4,
    "fourth": 5,
    "third": 6
}
print(has_duplicates)
#+end_src

Python could treat this as an error, keep the first entry, keep the last entry, or concatenate the entries somehow. As the output below shows, it chooses the third option:

#+RESULTS:
: {'third': 6, 'fourth': 5}

We can build a linter that finds dictionaries like has_duplicates with just a few lines of code and the ~Counter~ class from Python’s ~collections~ module (which implements a specialized dictionary that counts how many times a key has been seen).

We define a ~visit_Dict~ method for ~NodeVisitor~ that adds each constant key to the counter, then look for keys that have been seen more than once:

#+begin_src python :eval yes :noweb yes :tangle ./src/ch13/find_duplicate_keys.py
import ast
from collections import Counter

class FindDuplicateKeys(ast.NodeVisitor):
    def visit_Dict(self, node):
        seen = Counter()
        for key in node.keys:
            if isinstance(key, ast.Constant):
                seen[key.value] += 1
        problems = {k for (k,v) in seen.items() if v > 1}
        self.report(node, problems)
        self.generic_visit(node)

    def report(self, node, problems):
        if problems:
            msg = ', '.join(p for p in problems)
            print(f'duplicates key(s) {{{msg}}} at {node.lineno}')

tree = ast.parse("""
<<has_duplicate_keys>>
""")
duplicates = FindDuplicateKeys()
duplicates.visit(tree)
#+end_src

#+RESULTS:
: duplicates key(s) {fourth, third} at 2

#+caption: As Far As We Can Go
#+begin_quote
FindDuplicateKeys only considers constant keys, which means it won’t find duplicate keys that are created on the fly like this:

#+begin_src python
def label():
    return "label"

actually_has_duplicate_keys = {
    "label": 1,
    "la" + "bel": 2,
    label(): 3,
    "".join(["l", "a", "b", "e", "l"]): 4,
}
#+end_src

We could try adding more code to handle this, but there are so many different ways to generate keys on the fly that our linter couldn’t possibly catch them all.

The possibility of false negatives doesn’t mean that linting is useless, though: every problem that linting catches gives programmers more time to check for things that linters can’t find.
#+end_quote

*** Finding Unused Variables

Finding unused variables -- ones that are assigned values but never used -- is more challenging than our previous examples.

The problem is /scope/: a variable defined in a function or method might have the same name as one defined elsewhere, but they are different variables.

Let’s start by defining a class that handles variables in modules and functions. Since functions can be defined inside modules and other functions, the constructor for our class creates a list that we will /use as a stack to keep track of what scopes/ we’re currently in:

#+begin_src python :noweb yes :tangle ./src/ch13/find_unused_variables.py
import ast
import sys
<<Scope-14>>

class FindUnusedVariables(ast.NodeVisitor):
    def __init__(self):
        super().__init__()
        self.stack = []

    def visit_Module(self, node):
        self.search('global', node)

    def visit_FunctionDef(self, node):
        self.search(node.name, node)

    <<search, check>>

    <<visit_Name>>
#+end_src

We could just use a list of three values to record information for each scope, but using namedtuple (which also comes from Python’s collections module) tells readers explicitly what each scope consists of:

#+name: Scope-14
#+begin_src python
from collections import namedtuple

Scope = namedtuple("Scope", ["name", "load", "store"])
Scope(1,2,3)
# => Scope(name=1, load=2, store=3)
#+end_src

Each time we encounter a new scope we push a new ~Scope~ triple onto the stack with a name, a set to hold the variables that are used in the scope, and another set to hold the variables that are defined in the scope.

We then call ~NodeVisitor.generic_visitor~ to trigger recursion, pop the record we just pushed off the stack, and report any problems:

#+name: search, check
#+begin_src python
def search(self, name, node):
    self.stack.append(Scope(name, set(), set()))
    self.generic_visit(node)
    scope = self.stack.pop()
    self.check(scope)

def check(self, scope):
    unused = scope.store - scope.load
    if unused:
        names = ", ".join(sorted(unused))
        print(f'unused in {scope.name}: {names}')

#+end_src

We haven't yet been adding anything to our ~Scope~.

- The last part of the puzzle is ~visit_Name~.
  * If the variable’s value is being read, the node will have a property ~.ctx~ (short for “context”) of type =ast.Load=.
  * If the variable is being written to, the node’s ~.ctx~ property will be an instance of =ast.Store=.

Checking this property allows us to put the name in the right set in the scope that’s at the top of the stack:

#+name: visit_Name
#+begin_src python
def visit_Name(self, node):
    if isinstance(node.ctx, ast.Load):
        self.stack[-1].load.add(node.id)
    elif isinstance(node.ctx, ast.Store):
        self.stack[-1].store.add(node.id)
    else:
        assert False, f'Unknown context'
    self.generic_visit(node)

#+end_src

Once again, we can run this by reading the source of a program, converting it to an AST, constructing an instance of ~FindUnusedVariables~, and running its ~visit~ method:

#+begin_src python :tangle ./src/ch13/find_unused_variables.py
with open(sys.argv[1], "r") as reader:
    source = reader.read()
tree = ast.parse(source)
finder = FindUnusedVariables()
finder.visit(tree)
#+end_src

#+caption: a program that has some unused variables
#+begin_src python :eval yes :tangle ./src/ch13/has_unused_variables.py
used = 3
distractor = 2
not_used = used + distractor


def no_unused(param):
    result = 2 * param
    return result * not_used


def has_unused(param):
    used = 3 * param
    not_used = 2 * param
    distractor = "distraction"
    return used

print(no_unused(1))
#+end_src

#+RESULTS:
: 10

#+begin_src sh
uv run ./src/ch13/find_unused_variables.py ./src/ch13/has_unused_variables.py
#+end_src

#+RESULTS:
: unused in has_unused: distractor, not_used
: unused in global: not_used

- NOTE :: We are NOT finding ALL unused 'variables' (in a sense functions are also variables but we aren't checking for those).
  - Wrong :: ~not_used~ was utilised in the ~def no_unused~ function definition, but we are still saying that it wasn't used in the 'global' scope.

    To fix this, we need to add a loaded variable to not the topmost ~Scope~, but the scope that we get it from.

* Chapter 14: Page Layout
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/layout/
:header-args:python: :session ch14 :results output :async yes :eval no
:header-args:sh: :session ch14-sh :results output :async yes
:END:
** Summary
:PROPERTIES:
:ID:       98b2e49a-1738-47e8-9e77-172809a48b5c
:END:

- A layout engine places page elements based on their size and organization.
- Page elements are organized as a tree of basic blocks, rows, and columns.
- The layout engine calculates the position of each block based on its size and the position of its parent.
- Drawing blocks on /top of each other/ is an easy way to render them.

- Use multiple inheritance and *mixin classes* to inject methods into classes.

You might be reading this as HTML in your browser, as an e-book, or on the printed page.
In all three cases a layout engine took some text and some layout instructions and decided where to put each character and image.

To explore how they work, we will build a small layout engine based on [[https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html][Matt Brubeck’s tutorial]] and on Pavel Panchekha and Chris Harrelson’s book [[https://browser.engineering/][Web Browser Engineering]]. Since our focus is layout, we will create objects ourselves to represent DOM nodes rather than parsing HTML.

Real page layout systems do far more than what we have described, but all of them implement some kind of negotiation between containers and content.

#+caption: Page layout concept map
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_19-00-10_screenshot.png]]

** Theory
*** Sizing
:PROPERTIES:
:ID:       6ebc6cc0-e25a-49a9-9613-fba903f5adfe
:END:

Let’s start on easy mode without margins, padding, line-wrapping, or other complications. Everything we can put on the screen is represented as a rectangular cell, and every cell is either a row, a column, or a block.
A block has a fixed width and height:

#+begin_src python :tangle ./src/ch14/easy_mode.py
class Block:
    def __init__(self, width, height):
        self.width = width
        self.height = height

    def get_width(self):
        return self.width

    def get_height(self):
        return self.height

#+end_src

#+caption: The coordinate systems for screens puts (0, 0) in the upper-left corner
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-10-32_screenshot.png]]

A row arranges one or more cells horizontally; its width is the sum of the widths of its children, while its height is the height of its tallest child

#+caption: Calculating sizes of blocks with fixed height and width
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-11-07_screenshot.png]]

#+begin_src python :tangle ./src/ch14/easy_mode.py
class Row:
    def __init__(self, *children):
        self.children = list(children)

    def get_width(self):
        return sum([c.get_width() for c in self.children])

    def get_height(self):
        return max(
            [c.get_height() for c in self.children],
            default=0
        )

#+end_src

Finally, a column arranges one or more cells vertically: its width is the width of its widest child and its height is the sum of the heights of its children. (Here and elsewhere, we use the abbreviation col when referring to columns.)

#+begin_src python :tangle ./src/ch14/easy_mode.py
class Col:
    def __init__(self, *children):
        self.children = list(children)

    def get_width(self):
        return max(
            [c.get_width() for c in self.children],
            default=0
        )

    def get_height(self):
        return sum([c.get_height() for c in self.children])

#+end_src

Rows and columns nest inside one another.
A row cannot span two or more columns, and a column cannot cross the boundary between two rows.

- We can therefore represent our document as a tree and calculate the width and height of each cell every time we need it.

  - This is simple BUT /INEFFICIENT/: we could calculate both width and height at the same time and cache those values to avoid recalculation, but we called this “easy mode” for a reason.

As simple as it is, this code could still contain errors (and did during development), so we write some tests to check that it works properly before trying to build anything more complicated. One such test is:

#+begin_src python :tangle ./src/ch14/test_easy_mode.py
from easy_mode import Block, Col, Row

def test_lays_out_a_grid_of_rows_of_columns():
    fixture = Col(
        Row(Block(1, 2), Block(3, 4)),
        Row(Block(5, 6), Col(Block(7, 8), Block(9, 10)))
    )
    assert fixture.get_width() == 14
    assert fixture.get_height() == 22

#+end_src

#+begin_src sh
uvx pytest ./src/ch14/
#+end_src

#+RESULTS:
: ============================================= test session starts =============================================
: platform linux -- Python 3.12.11, pytest-8.4.2, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 1 item
:
: src/ch14/test_easy_mode.py .                                                                            [100%]
:
: ============================================== 1 passed in 0.00s ==============================================

*** Positioning
:PROPERTIES:
:ID:       05f64b0b-a24c-4109-a754-459837de29ef
:END:
Once we know how big cells are, we can figure out where to put them.

Suppose we start with the upper-left corner of the browser: upper because we lay out the page top-to-bottom and left because we are doing left-to-right layout.

#+caption: Laying out rows and columns of fixed-size blocks
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-18-40_screenshot.png]]

- If the cell is a block, we place it there.
- If the cell is a row, on the other hand, we get its height and then calculate its lower edge as y1 = y0 + height.
  We then place the first child’s upper-left corner at (x0, y1-height0), the second child’s at (x0 + width0, y1-height1), and so on
- Similarly, if the cell is a column, we place the first child at (x0, y0), the next at (x0, y0 + height0), and so on.

To save ourselves some work, we will derive the classes that know how to do layout from the classes we wrote before. Basic blocks are:

#+begin_src python :tangle ./src/ch14/placed.py
from easy_mode import Block, Col, Row

class PlacedBlock(Block):
    def __init__(self, width, height):
        super().__init__(width, height)
        self.x0 = None
        self.y0 = None

    def place(self, x0, y0):
        self.x0 = x0
        self.y0 = y0

    def report(self):
        return [
            "block",
            self.x0, self.y0,
            self.x0 + self.width, self.y0 + self.height
        ]

#+end_src

The constructor and reporting method for the PlacedCol class looks much the same. Its placement method is:

#+begin_src python :tangle ./src/ch14/placed.py
class PlacedCol(Col):
    def __init__(self, *children):
        super().__init__(*children)
        assert isinstance(self.children, list)
        self.x0 = None
        self.y1 = None

    def place(self, x0, y0):
        self.x0 = x0
        self.y0 = y0
        y_current = self.y0
        for child in self.children:
            child.place(x0, y_current)
            y_current += child.get_height()

    def report(self):
        return [
            "col",
            self.x0, self.y0,
            self.x0 + self.get_width(), self.y0 + self.get_height(),
        ] + [c.report() for c in self.children]

#+end_src

while

#+begin_src python :tangle ./src/ch14/placed.py
class PlacedRow(Row):
    def __init__(self, *children):
        super().__init__(*children)
        assert isinstance(self.children, list)
        self.x0 = None
        self.y0 = None

    def place(self, x0, y0):
        self.x0 = x0
        self.y0 = y0
        y1 = self.y0 + self.get_height()
        x_current = x0
        for child in self.children:
            child_y = y1 - child.get_height()
            child.place(x_current, child_y)
            x_current += child.get_width()

    def report(self):
        return [
            "row",
            self.x0,
            self.y0,
            self.x0 + self.get_width(),
            self.y0 + self.get_height(),
        ] + [c.report() for c in self.children]

#+end_src

Once again, we write and run some tests to check that everything is doing what it’s supposed to. One such test is:

#+begin_src python :tangle ./src/ch14/test_placed.py
from placed import (PlacedBlock as Block,
                    PlacedCol as Col,
                    PlacedRow as Row,
                    )

def test_places_a_column_of_two_blocks():
    fixture = Col(Block(1, 1), Block(2, 4))
    fixture.place(0, 0)
    assert fixture.report() == [
        "col",
        0, 0, 2, 5,
        ["block", 0, 0, 1, 1],
        ["block", 0, 1, 2, 5],
    ]

#+end_src

#+begin_src sh
uvx pytest ./src/ch14/
#+end_src

#+RESULTS:
: ============================================= test session starts =============================================
: platform linux -- Python 3.12.11, pytest-8.4.2, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 2 items
:
: src/ch14/test_easy_mode.py .                                                                            [ 50%]
: src/ch14/test_placed.py .                                                                               [100%]
:
: ============================================== 2 passed in 0.01s ==============================================

*** Rendering
:PROPERTIES:
:ID:       13b5a023-b868-43ac-add5-cf493da57d52
:END:

We drew blocks on graph paper to figure out the expected answers for the tests shown above.

We can do something similar in software by creating a “screen” of space characters and having each block draw itself in the right place. If we start at the root of the tree, children will overwrite the marks made by their parents, which will automatically produce the right appearance.

#+caption: Render blocks by drawing child nodes on top of parent nodes.
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-26-55_screenshot.png]]

A more sophisticated version of this called *z-buffering* used in 3D graphics keeps track of the visual depth of each pixel to draw objects correctly regardless of their order.
- z-buffering ::
  A drawing method that keeps track of the depth of what lies “under” each pixel so that it displays whatever is nearest to the observer.

Our “screen” is a list of lists of characters, with one inner list for each a row on the screen. (We use lists rather than strings so that we can overwrite characters in place.)

#+begin_src python :tangle ./src/ch14/render.py
def make_screen(width, height):
    screen = []
    for i in range(height):
        screen.append([" "] * width)
    return screen

#+end_src

We will use successive lower-case characters to show each block, i.e., the root block will draw itself using ‘a’, while its children will be ‘b’, ‘c’, and so on.

#+begin_src python :tangle ./src/ch14/render.py
def draw(screen, node, fill=None):
    fill = next_fill(fill)
    node.render(screen, fill) # We need to implement this !
    if hasattr(node, "children"): # Noice
        for child in node.children:
            fill = draw(screen, child, fill)
    return fill

def next_fill(fill):
    return "a" if fill is None else chr(ord(fill) + 1)

def render(root):
    root.place(0, 0)
    width = root.get_width()
    height = root.get_height()
    screen = make_screen(width, height)
    draw(screen, root)
    return "\n".join("".join(ch) for ch in screen)
#+end_src

- Note the:
  - usage of ~hasattr~ :)
  - usage of ~chr~ and ~ord~

To teach each kind of cell to render itself, we derive new classes from the ones we have and give each of those new classes a render method with the same signature. Since Python supports multiple inheritance, we can do this with a *mixin class*.
- mixin class ::
  A class that is not meant to be instantiated itself but which contains methods to be added to other classes (typically via *multiple inheritance*).

The ~Renderable~ mixin is:

#+begin_src python :tangle ./src/ch14/rendered.py
from placed import PlacedBlock, PlacedRow, PlacedCol

class Renderable:
    def render(self, screen, fill):
        for ix in range(self.get_width()):
            for iy in range(self.get_height()):
                screen[self.y0 + iy][self.x0 + ix] = fill

#+end_src

Using it, the new cell classes are simply:

#+begin_src python :tangle ./src/ch14/rendered.py
class RenderedBlock(PlacedBlock, Renderable):
    pass

class RenderedCol(PlacedCol, Renderable):
    pass

class RenderedRow(PlacedRow, Renderable):
    pass

#+end_src

#+caption: Using multiple inheritance and a mixin class to add methods.
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-31-19_screenshot.png]]

#+caption: (Not) The Right Way To Do It
#+begin_quote
If we were building a real layout engine, we would go back and create a class called ~Cell~ with this render method, then derive our ~Block~, ~Row~, and ~Col~ classes from that.

IN GENERAL, if two or more classes need to be able to do something, we should add the required method to their lowest common ancestor.

We’ve chosen not to do that in this case both:
- to show when and why mixin classes are sometimes useful, and
- so that we can build and test code incrementally.
#+end_quote

Simple tests are a little easier to read using rendering, though we still had to draw things on paper to figure out what to expect:

#+begin_src python :tangle ./src/ch14/test_rendered.py
from render import render
from rendered import (RenderedBlock as Block,
                      RenderedCol as Col,
                      RenderedRow as Row,
                      )

def test_renders_a_column_of_two_blocks():
    fixture = Col(Block(1, 1), Block(2, 4))
    fixture.place(0, 0)
    expected = "\n".join(["ba", "cc", "cc", "cc", "cc"])
    assert render(fixture) == expected

#+end_src

#+begin_src sh
uvx pytest ./src/ch14/
#+end_src

#+RESULTS:
#+begin_example
============================================= test session starts =============================================
platform linux -- Python 3.12.11, pytest-8.4.2, pluggy-1.6.0
rootdir: /home/nabeel/Documents/public/books/Software Design by Example
collected 3 items

src/ch14/test_easy_mode.py .                                                                            [ 33%]
src/ch14/test_placed.py .                                                                               [ 66%]
src/ch14/test_rendered.py .                                                                             [100%]

============================================== 3 passed in 0.01s ==============================================
#+end_example

- NOTE :: The fact that our tests are difficult to understand is a sign that we should do more testing.

  It would be very easy for us to get a wrong result and convince ourselves that it was correct; this kind of /confirmation bias/ is very common in software development.

*** Wrapping
:PROPERTIES:
:ID:       952f89fc-2d19-40c6-b264-885ee5a42af8
:END:

One of the biggest differences between a browser and a printed page is that the text in the browser wraps automatically as the window is resized. (The other, these days, is that the printed page doesn’t spy on us, though someone is undoubtedly working on that.)
Lol :)

- The first step in adding wrapping to our layout engine is to fix the width of a row.

  If the total width of the children is greater than the row’s width, the layout engine needs to wrap the children around.

  This assumes that:
  - columns can be made as tall as they need to be, i.e., that we can grow vertically to make up for limited space horizontally
  - none of a row’s children is wider than the width of the row so that each can fit in a row of its own if necessary

Our layout engine manages wrapping by transforming the tree.
- The height and width of blocks are fixed, so they become themselves.

- Columns become themselves as well, BUT since they have children that might need to wrap, the class representing columns needs a new method:

#+begin_src python :tangle ./src/ch14/wrapped.py
from placed import PlacedBlock, PlacedCol, PlacedRow

class WrappedBlock(PlacedBlock):
    def wrap(self):
        # NOICE
        return self

class WrappedCol(PlacedCol):
    def wrap(self):
        return PlacedCol(*[c.wrap() for c in self.children])

#+end_src

Rows do all the hard work. :)

Each original row is replaced with a new row that contains a single column with one or more rows, each of which is one “line” of wrapped cells.
- row :: becomes row -> col -> list of rows (lor)
  - NOTE :: unlike the below image each row of lor might contain more than one thing as long as they fit in the width of a single row.

#+caption: Wrapping rows by introducing a new row and column.
[[file:images/Chapter_14:_A_Code_Linter/2025-09-06_18-46-36_screenshot.png]]

This replacement is unnecessary when everything will fit on a single row, but it’s easiest to write the code that does it every time
(Here if everything did fit in the original row, we would still stransform it into a row->col->[row])

Our new wrappable row’s constructor takes a fixed width followed by the children and returns that fixed width when asked for its size:

#+begin_src python :noweb yes :tangle ./src/ch14/wrapped.py
class WrappedRow(PlacedRow):
    def __init__(self, width, *children):
        super().__init__(*children)
        assert width >= 0, 'Need non-negative width'
        self.width = width

    def get_width(self):
        return self.width

    <<def wrap-14>>

    <<def _bucket-14>>
#+end_src

Wrapping puts the row’s children into buckets, and then converts the buckets to a row of a column of rows:

#+name: def wrap-14
#+begin_src python
def wrap(self):
    children = [c.wrap() for c in self.children]
    rows = self._bucket(children)
    new_rows = [PlacedRow(*bucket) for bucket in rows]
    new_col = PlacedCol(*new_rows)
    return PlacedRow(new_col)
#+end_src

To bucket the children, we add them one at a time to a temporary list. If adding another node would make the total width of the nodes in that list too large, we use that node to start a new temporary list:

#+name: def _bucket-14
#+begin_src python
def _bucket(self, children):
    result = []
    current_row = []
    current_x = 0

    for child in children:
        child_width = child.get_width()
        if current_x + child_width <= self.width:
            current_row.append(child)
            current_x += child_width
        else:
            result.append(current_row)
            current_row = [child]
            current_x = child_width
            pass

    result.append(current_row)
    return result
#+end_src

Once again, we bring forward all the previous tests and write some new ones to test the functionality we’ve added:

#+begin_src python :tangle ./src/ch14/test_wrapped.py
from wrapped import WrappedBlock, WrappedRow, WrappedCol

def test_wrap_a_row_of_two_blocks_that_do_not_fit_on_one_row():
    fixture = WrappedRow(3, WrappedBlock(2, 1), WrappedBlock(2, 1))
    wrapped = fixture.wrap()
    wrapped.place(0, 0)
    assert wrapped.report() == [
        "row",
        0, 0, 2, 2,
        [
            "col",
            0, 0, 2, 2,
            ["row", 0, 0, 2, 1, ["block", 0, 0, 2, 1]],
            ["row", 0, 1, 2, 2, ["block", 0, 1, 2, 2]],
        ],
    ]

#+end_src

#+begin_src sh
uvx pytest ./src/ch14/
#+end_src

#+RESULTS:
#+begin_example
============================================= test session starts =============================================
platform linux -- Python 3.12.11, pytest-8.4.2, pluggy-1.6.0
rootdir: /home/nabeel/Documents/public/books/Software Design by Example
collected 4 items

src/ch14/test_easy_mode.py .                                                                            [ 25%]
src/ch14/test_placed.py .                                                                               [ 50%]
src/ch14/test_rendered.py .                                                                             [ 75%]
src/ch14/test_wrapped.py .                                                                              [100%]

============================================== 4 passed in 0.01s ==============================================
#+end_example

- NOTE :: We could have had columns handle resizing rather than rows, but we (probably) don’t need to make both resizeable.

  This is an example of *intrinsic complexity*: the problem REALLY is this hard, so something has to deal with it somewhere.

  Programs often contain *accidental complexity* as well, which can be removed if people are willing to accept change. In practice, that often means that it sticks around longer than it should.

#+caption: The Liskov Substitution Principal
#+begin_quote
We are able to re-use tests as our code evolved because of the _Liskov Substitution Principle_, which states that it should be possible to replace objects in a program with objects of derived classes without breaking anything.

In order to satisfy this principle:

- New code must handle the same set of inputs as the old code, though it may be able to process more inputs as well

- Conversely, its output must be a subset of what the old code produced so that whatever is downstream from it won’t be surprised.

Thinking in these terms leads to the methodology called /design by contract/ discussed in [[*Chapter 2: Objects and Classes][Chapter 2: Objects and Classes]].
#+end_quote

* Chapter 15: Performance Profiling
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/perf/
:header-args:python: :session ch15 :results output :async yes :eval no
:header-args:sh: :session ch15-sh :results output :async yes
:END:

Not worthy of notes.

* Chapter 16: Object Persistence
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/persist/
:header-args:python: :session ch16 :results output :async yes :eval no
:header-args:sh: :session ch16-sh :results output :async yes
:END:

** Summary
:PROPERTIES:
:ID:       4674411a-5788-445c-a06c-1c13b7342f87
:END:

- A persistence framework saves and restores objects.

- Persistence must handle /aliasing and circularity/.

- Users should be able to extend persistence to handle objects of their own types.
- Software designs should be open for extension but closed for modification.

#+caption: Concepts for persistence
[[file:images/Chapter_16:_Object_Persistence/2025-09-14_17-09-10_screenshot.png]]

*Q.* Version control can keep track of our files, but what should we put in them ?

Plain text works well for things like this chapter, but the data structures used to represent HTML ([[*Chapter 11: An HTML Validator][Chapter 11: An HTML Validator]]) or the state of a game aren’t easy to represent in prose.

Another option is to store objects, i.e., to save a list of dictionaries as-is rather than flattening (marshelling/serializing) it into rows and columns.
Python's [[https://docs.python.org/3/library/pickle.html][pickle]] module does this in a Python-specific way, while the [[https://docs.python.org/3/library/json.html][json]] module saves SOME KINDS OF DATA as text formatted like JavaScript objects. As odd as it may seem, this has become a cross-language standard.

The phrase “some kinds of data” is the most important part of the preceding paragraph. Since programs can define new classes, a persistence framework has to choose one of the following:

1. Only handle built-in types, or even more strictly, only handle types that are common across many languages, so that data saved by Python can be read by JavaScript and vice versa.

2. Provide a way for programs to convert from user-defined types to built-in types and then save those.

   This option is less restrictive than the first but can lead to some information being lost. For example, if instances of a program’s /User/ class are saved as dictionaries, the program that reads data may wind up with dictionaries instead of users.

3. Save class definitions as well as objects’ values so that when a program reads saved data it can reconstruct the classes and then create fully functional instances of them.

   This choice is the most powerful, but it is also the hardest to implement, particularly across languages.

   It is also the _RISKIEST_: if a program is running third-party code in order to restore objects, /it has to trust that code not to do anything malicious./

This chapter starts by implementing the first option (built-in types only), then extends it to handle objects that the data structure refers to in several places (which JSON does not).

To keep parsing and testing simple, our framework will store everything as text with one value per line; we will look at non-text options in Chapter 17, and at how to handle user-defined types in Appendix B.

** Theory
*** Built-in types
:PROPERTIES:
:ID:       bd1f3e9a-b403-4e59-ba43-f32f1673e0e4
:END:

The first thing we need to do is specify our data format.

We will store each atomic value on a line of its own with a type name and a value separated by a colon:
#+begin_src python
bool:True
int:123
#+end_src

Since we are storing things as text, we have to handle strings carefully: for example, we might need to save the string "str:something" and later be able to tell that it isn’t the string "something"
(it is actually the string 'str:something').

We do this by splitting strings on newline characters and saving the number of lines, followed by the actual data:
#+begin_example
# input
this is
two lines
#+end_example

#+begin_src python
# output
str:2
this is
two lines # even if we have 'str:something' here it would have a text that is of the part of the original string that spans two lines.
#+end_src

The function save handles three of Python’s built-in types to start with:

#+begin_src python :noweb yes :tangle ./src/ch16/builtin.py
def save(writer, thing):
    if isinstance(thing, bool):
        print(f'bool:{thing}', file=writer)

    elif isinstance(thing, float):
        print(f'float:{thing}', file=writer)

    elif isinstance(thing, int):
        print(f'int:{thing}', file=writer)

    elif isinstance(thing, str):
        values = thing.split('\n')
        print(f'str:{len(values)}', file=writer)
        for value in values:
            print(value, file=writer)

    <<save-list-ch16>>

    <<save-dict-ch16>>

    else:
        raise ValueError(f'unknown type of thing {type(thing)}')

#+end_src

The function that loads data starts by reading a single line, stripping off the newline at the end (which is added automatically by the ~print~ statement in ~save~), and then splitting the line on colons. After checking that there are two fields, it uses the type name in the first field to decide how to handle the second:

#+begin_src python :noweb yes :tangle ./src/ch16/builtin.py
def load(reader):
    line = reader.readline()[:-1] # ignore the 'newline' character
    assert line, 'Nothing to read'
    fields = line.split(':', maxplit=1) # split of the first ':' from left to right
    assert len(fields) == 2, f'Badly formed line {line}'
    key, value = fields

    if key == 'bool':
        names = {'True': True,
                 'False': False,
                 }
        assert value in names, f'Unknown boolean {value}'
        return names[value]

    elif key == 'float':
        return float(value) # value is a string

    elif key == 'int':
        return int(value)

    elif key == 'str':
        # Unlike list and dict, the 'str:length'
        # is not something that to load we can call the 'load'
        # function recursively
        return '\n'.join([reader.readline()[:-1] # ignore the 'newline' character
                          for _ in range(int(value))])

    <<load-list-ch16>>

    <<load-dict-ch16>>

    else:
        raise ValueError(f'unknown type of thing {line}')

#+end_src

#+name: Figure 16.1
#+caption: Saving nested data structures
[[file:images/Chapter_16:_Object_Persistence/2025-09-14_17-25-04_screenshot.png]]

Saving a list is almost as easy: we save the number of items in the list, and then save each item with a recursive call to save.

For example, the list [55, True, 2.71] is saved as shown in [[Figure 16.1]]. The code to do this is:

#+name: save-list-ch16
#+begin_src python
elif isinstance(thing, list):
    print(f'list:{len(thing)}', file=writer)
    for item in thing:
        save(writer, item)
#+end_src

while to load a list, we just read the specified number of items:

#+name: load-list-ch16
#+begin_src python
elif key == 'list':
    return [load(reader) for _ in range(int(value))]
#+end_src

- NOTE :: that ~save~ and ~load~ don’t need to know what kinds of values are in the list.
  Each recursive call advances the input or output stream by precisely as many lines as it needs to.
  As a result, this approach should handle empty lists and nested lists without any extra work.

Our functions handle sets in exactly the same way as lists; the only difference is using the keyword ~set~ instead of the keyword ~list~ in the opening line. To save a dictionary, we save the number of entries and then save each key and value in turn:

#+name: save-dict-ch16
#+begin_src python
elif isinstance(thing, dict):
    print(f'dict:{len(thing)}', file=writer)
    for key, value in thing.items():
        save(writer, key)
        save(writer, value)
#+end_src

#+name: load-dict-ch16
#+begin_src python
elif key == 'dict':
    return {load(reader): load(reader) for _ in range(int(value))}
#+end_src

With this machinery in place, we can save our first data structure:
#+begin_src python :tangle ./src/ch16/save_builtin.py
import sys
from builtin import save
save(sys.stdout, [False, 3.14, "hello", {"left": 1, "right": [2, 3]}])
#+end_src

#+begin_src sh
uv run ./src/ch16/save_builtin.py
#+end_src

#+RESULTS:
#+begin_example
list:4
bool:False
float:3.14
str:1
hello
dict:2
str:1
left
int:1
str:1
right
list:2
int:2
int:3
#+end_example

We now need to write some unit tests.
We will use two tricks when doing this:

1. The =StringIO= class from Python’s [[https://docs.python.org/3/library/io.html][io]] module allows us to read from strings and write to them using the functions we normally use to read and write files.

   - Nice :: Using this lets us run our tests without creating lots of little files as a side effect.
   (Hmm, like we used pyfakefs for an in-memory file system)

2. The ~dedent~ (Remove any common leading whitespace from every line in `text`) function from Python's [[https://docs.python.org/3/library/textwrap.html][textwrap]] module removes leading indentation from the body of a string.

   As the example below shows, dedent allows us to indent a fixture the same way we indent our Python code, which makes the test easier to read.

#+begin_src python :tangle ./src/ch16/test_builtin.py
from io import StringIO
from textwrap import dedent
from builtin import save

def test_save_list_flat():
    fixture = [0, False]
    expected = dedent("""\
    list:2
    int:0
    bool:False
    """)
    output = StringIO()
    save(output, fixture)
    assert output.getvalue() == expected
#+end_src

#+begin_src sh
uvx pytest ./src/ch16/test_builtin.py
#+end_src

#+RESULTS:
: ============================================= test session starts =============================================
: platform linux -- Python 3.12.11, pytest-8.4.2, pluggy-1.6.0
: rootdir: /home/nabeel/Documents/public/books/Software Design by Example
: collected 1 item
:
: src/ch16/test_builtin.py .                                                                              [100%]
:
: ============================================== 1 passed in 0.00s ==============================================

*** Converting to Classes

The save and load functions we built in the previous section work, but as we were extending them we had to modify their internals every time we wanted to do something new.
(True)

- Open-Closed Principle ::
  A design rule stating that software should be open for extension but closed for modification, i.e., it should be possible to extend functionality without having to rewrite existing code.

*Open-Closed Principle* allows old code to use new code, BUT only if our design permits the kinds of extensions people are going to want to make. (/Even then/, it OFTEN leads to deep class hierarchies that can be hard for the next programmer to understand.)

Since we can’t anticipate everything, it is normal to have to revise a design the first two or three times we try to extend it. The things we make learn how to do things better as we use them.

In this case, we can follow the Open-Closed Principle by rewriting our functions as classes and by using yet another form of *dynamic dispatch* to handle each item so that we don’t have to modify a multi-way if statement each time we add a new capability.

If we have an object =obj=, then ~hasattr(obj, "name")~ tells us whether that object has an attribute called "name". If it does, ~getattr(obj, "name")~ returns that attribute’s value; if that attribute happens to be a method, we can then call it like a function:

#+begin_src python :eval yes :tangle ./src/ch16/attr.py
class Example:
    def __init__(self, label):
        self.label = label

    def get_size(self):
        return len(self.label)

ex = Example('thing')
print('ex has missing', hasattr(ex, 'missing'))
print("ex has label", hasattr(ex, "label"), "with value", getattr(ex, "label"))
print("ex has get_size", hasattr(ex, "get_size"))
method = getattr(ex, "get_size")
print("result of calling method", method())
#+end_src

#+RESULTS:
: ex has missing False
: ex has label True with value thing
: ex has get_size True
: result of calling method 5

Using this, the core of our saving class is:

#+begin_src python :noweb yes :tangle ./src/ch16/objects.py
class SaveObjects:
    def __init__(self, writer):
        self.write = writer

    def save(self, thing):
        typename = type(thing).__name__
        method = f'save_{typename}'
        assert hasattr(self, method), \
            f'Unknown object type {typename}'
        getattr(self, method)(thing)

    <<def save_int>>

    <<def save_str>>

#+end_src

We have called this class ~SaveObjects~ instead of just ~Save~ because we are going to create other variations on it. ~SaveObjects.save~ figures out which method to call to save a particular thing by constructing a name based on the thing’s type, checking whether that method exists, and then calling it.

/As in the previous example of dynamic dispatch/, the methods that handle specific items MUST ALL HAVE the same signature so that they can be called interchangeably. For example, the methods that write integers and strings are:

#+name: def save_int
#+begin_src python
def save_int(self, thing):
    self._write('int', thing)
#+end_src

#+name: def save_str
#+begin_src python
def save_str(self, thing):
    lines = thing.split('\n')
    self._write('str', len(lines))
    for line in lines:
        print(line, file=self.writer)
#+end_src

~LoadObjects.load~ combines dynamic dispatch with the string handling of our original ~load~ function:

#+begin_src python :noweb yes :tangle ./src/ch16/objects.py
class LoadObjects:
    def __init__(self, reader):
        self.reader = reader

    def load(self):
        line = self.reader.readline()[:-1]
        fields = line.split(":", maxsplit=1)
        assert len(fields) == 2, f"Badly-formed line {line}"
        key, value = fields

        method = f"load_{key}"
        assert hasattr(self, method), f"Unknown object type {key}"
        return getattr(self, method)(value)

    <<def load_float>>

#+end_src

The methods that load individual items are even simpler. For example, we load a floating-point number like this:

#+name: def load_float
#+begin_src python
def load_float(self, value):
    return float(value)
#+end_src

*** Aliasing
:PROPERTIES:
:ID:       2c0ce102-77a4-4319-8804-46d77c14a5f9
:END:

Consider the two lines of code below, which created the data structure shown in [[Figure 16.2]].

#+begin_src python
shared = ['content']
fixture = [shared, shared]
# => fixture = [['content'], ['content']]
# We save 1. shared, then 2. fixture by calling SaveObjects.save on these variables
#+end_src

#+name: Figure 16.2
#+caption: Saving aliased data without respecting aliases
[[file:images/Chapter_16:_Object_Persistence/2025-09-14_18-48-04_screenshot.png]]

If we save this structure and then reload it using what we have built so far, we will wind up with two copies of the list containing the string "content" instead of one. This won’t be a problem _if we only_ ever read the reloaded data, BUT if we modify the new copy of ~fixture[0]~, we won’t see that change reflected in ~fixture[1]~, where we would have seen the change in the original data structure:

The problem is that the list shared is *aliased*, i.e., there are two or more references to it. To reconstruct the original data correctly, we need to:

1. keep track of everything we have saved
2. save a marker instead of the object itself when we try to save it a second time; and
3. reverse this process when loading data

We can keep track of the things we have saved using Python’s built-in ~id~ function, which returns a unique ID for every object in the program. For example, even if two lists contain exactly the same values, ~id~ will report different IDs for those lists because they’re stored in different locations in memory. We can use this to:

1. store the IDs of all the objects we have already saved in a set, and then
2. write a special entry with the keyword /alias/ and its unique ID when we see an object for the second time.

Here's the start of ~SaveAlias~:

#+begin_src python :noweb yes :tangle ./src/ch16/aliasing_wrong.py
from objects import SaveObjects, LoadObjects

class SaveAlias(SaveObjects):
    def __init__(self, writer):
        super().__init__(writer)
        self.seen = set()

    def save(self, thing):
        thing_id = id(thing)
        if thing_id in seen:
            self._write('alias', thing_id, "")
            return

        self.seen.add(thing_id)
        typename = type(thing).__name__
        method = f'save_{typename}'
        assert hasattr(self, method), f"Unknown object type {typename}"
        getattr(self, method)(thing)

    <<def save_list>>

#+end_src

Its constructor creates an empty set of IDs seen so far. If ~SaveAlias.save~ notices that the object it’s about to save has been saved before, it writes a line like this:

#+begin_example
alias:12345678:
#+end_example

where 12345678 is the object's ID.

*Q.* Why is there a colon at the end of the line alias:12345678: when we create an alias marker ?
*A.* This seems to be consistent with the new way we will save objects, for examle, /int:12321432:5/

If the object hasn’t been seen before, SaveAlias saves the object’s type, its ID, and either its value or its length:

#+name: def save_list
#+begin_src python
def save_list(self, thing):
    self._write('list', id(thing), len(thing))
    for item in thing:
        self.save(item)
#+end_src

~SaveAlias._list~ is a little different from ~SaveObjects._list~ because it has to save each object’s identifier along with its type and its value or length.

Our ~LoadAlias~ class needs a similar change compared to ~LoadObjects~. The first version is shown below; as we will see, it contains a subtle bug:

#+begin_src python :noweb yes :tangle ./src/ch16/aliasing_wrong.py
class LoadAlias(LoadObjects):
    def __init__(self, reader):
        super().__init__(reader)
        self.seen = {} # dict (not a 'set' like in ReadAlias)

    def load(self):
        line = self.reader.readline()[:-1]
        assert line, "Nothing to read"
        fields = line.split(":", maxsplit=2)
        assert len(fields) == 3, f"Badly-formed line {line}"
        key, ident, value = fields

        # the lines below contain a bug
        # Q. What is the bug ???
        if key == 'alias':
            assert ident in self.seen
            return self.seen[ident]

        method = f'load_{key}'
        assert hasattr(self, method), f"Unknown object type {key}"
        result = getattr(self, method)(value)
        self.seen[ident] = result
        return result
#+end_src

The first test of our new code is:

#+begin_src python :tangle ./src/ch16/test_aliasing_wrong.py
from io import StringIO
from aliasing_wrong import SaveAlias, LoadAlias

def test_aliasing_no_aliasing():
    fixture = ['a', {'b': True, 7: {'c', 'd'}}]
    assert roundtrip(fixture) == fixture

def roundtrip(fixture)    :
    writer = StringIO()
    SaveAlias(writer).save(fixture)
    reader = StringIO(writer.getvalue())
    return LoadAlias(reader).load()

#+end_src

There isn’t any aliasing in the test case, but that’s deliberate: we want to make sure we haven’t broken code that was working before we move on. Here’s a test that actually includes some aliasing:

#+begin_src python :tangle ./src/ch16/test_aliasing_wrong.py
def test_aliasing_shared_child():
    shared = ['content']
    fixture = [shared, shared]
    result = roundtrip(fixture)
    assert result == fixture
    assert id(result[0]) == id(result[1])
    result[0][0] = 'changed'
    assert result[1][0] == 'changed'
#+end_src

It checks that the aliased sub-list is actually aliased after the data is restored, then checks that changes to the sub-list through one alias show up through the other. The second check ought to be redundant, but it’s still comforting.

There’s one more case to check, and unfortunately it reveals a bug. The two lines:

#+begin_src python
fixture = []
fixture.append(fixture)
#+end_src

creates the data structure shown in [[Figure 16.3]] , in which an object contains a reference to itself.

Our code /ought to/ handle this case BUT DOESN’T: when we try to read in the saved data, ~LoadAlias.load~ sees the alias line but then says it can’t find the object being referred to.

#+name: Figure 16.3
#+caption: A data structure that contains a refrence to itself
[[file:images/Chapter_16:_Object_Persistence/2025-09-21_13-56-25_screenshot.png]]

The problem is these lines in LoadAlias.load marked as containing a bug, in combination with these lines inherited from LoadObjects:

#+begin_src python
def load_list(self, value):
    return [self.load() for _ in range(int(value))]
#+end_src

Let's trace the execution for the saved data:

#+begin_src python
list:4484025600:1
alias:4484025600:
#+end_src

1. The first line tells us that there’s a list whose ID is 4484025600 so we ~LoadObjects._list~ to load a list of one element.

2. ~LoadObjects._list~ called ~LoadAlias.load~ recursively to load that one element.

3. ~LoadAlias.load~ reads the second line of saved data, which tells it to re-use the data whose ID is 4484025600.

   But ~LoadObjects._list~ hasn’t created that list yet -- it is still reading the elements -- so ~LoadAlias.load~ hasn’t added the list to seen.

The solution is to reorder the operations, which UNFORTUNATELY means writing new versions of all the methods defined in ~LoadObjects~. The new implementation of ~_list~ is:

#+begin_src python
def load_list(self, ident, length):
    result = []
    self.seen[ident] = result
    for _ in range(int(length)):
        result.append(self.load())
    return result
#+end_src

This method creates the list it's going to return, adds that list to the seen dictionary immediately, and THEN loads list items recursively.

We have to pass it the ID of the list to use as key in ~seen~, and we have to use a loop rather than a list comprehension, but the changes o ~save_set~ and ~save_dict~ follow exactly the same pattern.

* TODO Chapter 17: Binary Data
:PROPERTIES:
:ref: https://third-bit.com/sdxpy/binary/
:header-args:python: :session ch17 :results output :async yes :eval no
:header-args:sh: :session ch17-sh :results output :async yes
:END:
